{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d103a174-ac76-4f10-a338-706601a9b112",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from collections import Counter\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "from groq import Groq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54aa2db1-6f12-4089-921e-4488b53f5a27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cache_dir = \"../cache/\"\n",
    "os.environ['TRANSFORMERS_CACHE'] = cache_dir\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = \"false\"\n",
    "os.environ['OPENAI_API_KEY'] = 'openai-api-key-here'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0598cf-a9c9-4099-b3a0-45d7b423c79f",
   "metadata": {},
   "source": [
    "## The below is API script to get labels from GPT-4o-mini\n",
    "\n",
    "We send multiple sentences at once to save token usage cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b9b33da-3815-446b-a1c0-928537bf9892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 sentences sentiment result: sentiments=[SentimentAnalysisResponse(sentiment='Negative'), SentimentAnalysisResponse(sentiment='Neutral'), SentimentAnalysisResponse(sentiment='Positive'), SentimentAnalysisResponse(sentiment='Neutral'), SentimentAnalysisResponse(sentiment='Positive'), SentimentAnalysisResponse(sentiment='Neutral'), SentimentAnalysisResponse(sentiment='Neutral'), SentimentAnalysisResponse(sentiment='Neutral')]\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Optional\n",
    "from tqdm import tqdm\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Define the schema for sentiment analysis\n",
    "class SentimentAnalysisResponse(BaseModel):\n",
    "    sentiment: str = Field(description=\"The sentiment of the sentence (Positive, Negative, or Neutral)\")\n",
    "\n",
    "class Data(BaseModel):\n",
    "    \"\"\"Extracted data about sentences.\"\"\"\n",
    "    sentiments: List[SentimentAnalysisResponse]\n",
    "\n",
    "# Define the prompt template\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"Your task is to analyze the provided sentences written in African American English and identify the sentiment expressed by the author. \n",
    "            The sentiment should be classified as Positive, Negative, or Neutral for each sentence.\"\"\"\n",
    "        ),\n",
    "        (\"user\", \"{sentences}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the language model\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Create the runnable chain\n",
    "runnable = chat_template | model.with_structured_output(schema=Data)\n",
    "runnable_single = chat_template | model.with_structured_output(schema=SentimentAnalysisResponse)\n",
    "\n",
    "dataset = pd.read_csv('2000-5000_sentences.csv')[\"text\"]\n",
    "\n",
    "## Testing on first 10 sentences\n",
    "result = runnable.invoke({\"sentences\" : \"\\n\".join(dataset[:10].to_list())})\n",
    "\n",
    "print(f\"First 10 sentences sentiment result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0b08167-4189-4d59-a8e0-379ecad51801",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [04:09<00:00,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled dataset saved to ./labeled/GPT-4o-mini-Labels.csv\n",
      "Failed indices saved to ./labeled/failed_indices.csv\n",
      "Number of successfully processed sentences: 1510\n",
      "Number of failed sentences: 1490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store the sentiments and their corresponding indices\n",
    "all_sentiments = []\n",
    "processed_indices = []\n",
    "failed_indices = []\n",
    "\n",
    "# Process the dataset in batches of 10\n",
    "for i in tqdm(range(0, len(dataset), 10)):\n",
    "    batch = dataset[i:i+10].to_list()\n",
    "    batch_indices = list(range(i, min(i+10, len(dataset))))\n",
    "    \n",
    "    try:\n",
    "        result = runnable.invoke({\"sentences\": \"\\n\".join(batch)})\n",
    "        \n",
    "        # Check if the number of returned sentiments matches the batch size\n",
    "        if len(result.sentiments) == len(batch):\n",
    "            all_sentiments.extend([response.sentiment for response in result.sentiments])\n",
    "            processed_indices.extend(batch_indices)\n",
    "        else:\n",
    "            # If the number of sentiments doesn't match, mark all as failed\n",
    "            failed_indices.extend(batch_indices)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {i}-{i+9}: {str(e)}\")\n",
    "        failed_indices.extend(batch_indices)\n",
    "\n",
    "# Create a new dataframe with successfully processed sentences and sentiments\n",
    "labeled_df = pd.DataFrame({\n",
    "    'index': processed_indices,\n",
    "    'text': dataset.iloc[processed_indices],\n",
    "    'sentiment': all_sentiments\n",
    "})\n",
    "\n",
    "# Sort the dataframe by the original index\n",
    "labeled_df = labeled_df.sort_values('index').reset_index(drop=True)\n",
    "\n",
    "# Save the labeled dataset to a CSV file\n",
    "output_path = './labeled/GPT-4o-mini-Labels.csv'\n",
    "labeled_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Labeled dataset saved to {output_path}\")\n",
    "\n",
    "# Save the failed indices to a separate file\n",
    "failed_indices_path = './labeled/failed_indices.csv'\n",
    "pd.DataFrame({'failed_index': failed_indices}).to_csv(failed_indices_path, index=False)\n",
    "\n",
    "print(f\"Failed indices saved to {failed_indices_path}\")\n",
    "print(f\"Number of successfully processed sentences: {len(processed_indices)}\")\n",
    "print(f\"Number of failed sentences: {len(failed_indices)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4608966b-78f1-44cf-b56e-45440cb2a635",
   "metadata": {},
   "source": [
    "## Processing indcies that were not parsed correctly in first iteration of the API call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92156b02-5035-4d92-917f-499229988d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 298/298 [03:13<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete labeled dataset saved to ./labeled/complete-2000-GPT-4o-mini.csv\n",
      "Total processed sentences: 3000\n",
      "Successfully labeled sentences: 2810\n",
      "Failed sentences: 190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the previously processed data\n",
    "labeled_df = pd.read_csv('./labeled/GPT-4o-mini-Labels.csv')\n",
    "failed_indices = pd.read_csv('./labeled/failed_indices.csv')['failed_index'].tolist()\n",
    "\n",
    "# Load the original dataset\n",
    "original_dataset = pd.read_csv('2000-5000_sentences.csv')[\"text\"]\n",
    "\n",
    "# Initialize lists to store the new sentiments and their corresponding indices\n",
    "new_sentiments = []\n",
    "new_processed_indices = []\n",
    "still_failed_indices = []\n",
    "\n",
    "# Process the failed sentences\n",
    "for i in tqdm(range(0, len(failed_indices), 5)):\n",
    "    batch_indices = failed_indices[i:i+5]\n",
    "    batch = original_dataset.iloc[batch_indices].tolist()\n",
    "    \n",
    "    try:\n",
    "        result = runnable.invoke({\"sentences\": \"\\n\".join(batch)})\n",
    "        \n",
    "        # Check if the number of returned sentiments matches the batch size\n",
    "        if len(result.sentiments) == len(batch):\n",
    "            new_sentiments.extend([response.sentiment for response in result.sentiments])\n",
    "            new_processed_indices.extend(batch_indices)\n",
    "        else:\n",
    "            # If the number of sentiments doesn't match, mark all as still failed\n",
    "            still_failed_indices.extend(batch_indices)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {i}-{i+4}: {str(e)}\")\n",
    "        still_failed_indices.extend(batch_indices)\n",
    "\n",
    "# Create a new dataframe with newly processed sentences and sentiments\n",
    "new_labeled_df = pd.DataFrame({\n",
    "    'index': new_processed_indices,\n",
    "    'text': original_dataset.iloc[new_processed_indices],\n",
    "    'sentiment': new_sentiments\n",
    "})\n",
    "\n",
    "# Combine the previously processed data with the newly processed data\n",
    "combined_df = pd.concat([labeled_df, new_labeled_df], ignore_index=True)\n",
    "\n",
    "# Sort the dataframe by the original index and reset the index\n",
    "combined_df = combined_df.sort_values('index').reset_index(drop=True)\n",
    "\n",
    "# If there are still failed indices, add them to the combined dataframe with NaN sentiment\n",
    "if still_failed_indices:\n",
    "    failed_df = pd.DataFrame({\n",
    "        'index': still_failed_indices,\n",
    "        'text': original_dataset.iloc[still_failed_indices],\n",
    "        'sentiment': pd.NA\n",
    "    })\n",
    "    combined_df = pd.concat([combined_df, failed_df], ignore_index=True)\n",
    "    combined_df = combined_df.sort_values('index').reset_index(drop=True)\n",
    "\n",
    "# Save the complete labeled dataset to a CSV file\n",
    "output_path = './labeled/complete-2000-GPT-4o-mini.csv'\n",
    "combined_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Complete labeled dataset saved to {output_path}\")\n",
    "print(f\"Total processed sentences: {len(combined_df)}\")\n",
    "print(f\"Successfully labeled sentences: {combined_df['sentiment'].notna().sum()}\")\n",
    "print(f\"Failed sentences: {combined_df['sentiment'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7619f670-09b6-42ab-91ed-a9013d51142f",
   "metadata": {},
   "source": [
    "### Individualy calling the API for the 190 falied indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4de55e8b-4639-4064-967b-71996231f431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated complete labeled dataset saved to ./labeled/complete-2000-GPT-4o-mini-final.csv\n",
      "Total processed sentences: 3000\n",
      "Successfully labeled sentences: 3000\n",
      "Failed sentences: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the complete labeled dataset\n",
    "combined_df = pd.read_csv('./labeled/complete-2000-GPT-4o-mini.csv')\n",
    "\n",
    "# Apply the lambda function to process the indices where sentiment is NaN\n",
    "combined_df['sentiment'] = combined_df.apply(\n",
    "    lambda row: runnable_single.invoke({\"sentences\": row['text']}).sentiment \n",
    "    if pd.isna(row['sentiment']) else row['sentiment'], \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Save the updated complete labeled dataset\n",
    "output_path = './labeled/complete-2000-GPT-4o-mini-final.csv'\n",
    "combined_df.to_csv(output_path, index=False)\n",
    "\n",
    "# Display the summary of the updated dataset\n",
    "updated_total = len(combined_df)\n",
    "updated_successful = combined_df['sentiment'].notna().sum()\n",
    "updated_failed = combined_df['sentiment'].isna().sum()\n",
    "\n",
    "print(f\"Updated complete labeled dataset saved to {output_path}\")\n",
    "print(f\"Total processed sentences: {updated_total}\")\n",
    "print(f\"Successfully labeled sentences: {updated_successful}\")\n",
    "print(f\"Failed sentences: {updated_failed}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df79542d-bd4f-4a3c-9378-6c4c61218705",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[[\"text\", \"sentiment\"]].to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cab64fa-dc91-4938-ae26-c5c1ff21b54a",
   "metadata": {},
   "source": [
    "_________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d801c1b1-2dd2-44b8-96d1-a45d1f9dbff7",
   "metadata": {},
   "source": [
    "## Now we will translate the AAE sentences to SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e383a11-279f-43a9-b9e2-fd1d2b748f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardEnglish(BaseModel):\n",
    "    standard_english: str = Field(description=\"The tweet converted into Standard American English.\")\n",
    "\n",
    "class Data(BaseModel):\n",
    "    \"\"\"Convert the list of tweets provided to standard american english.\"\"\"\n",
    "    standard_english_tweets: List[StandardEnglish] = Field(description=\"The list of converted tweets by order of the sentences given.\")\n",
    "\n",
    "# Define the prompt template\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You will be given a list of tweets extracted from twitter accounts belonging to African American individuals. Your task is to convert the given tweet to Standard American English.\"\"\"\n",
    "        ),\n",
    "        (\"user\", \"{sentences}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the language model\n",
    "# model = ChatAnthropic(model=\"claude-3-haiku-20240307\", timeout=None,\n",
    "#     max_retries=2, temperature=0)\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", timeout=None,\n",
    "    max_retries=2, temperature=0)\n",
    "\n",
    "# Create the runnable chain\n",
    "runnable = chat_template | model.with_structured_output(schema=Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0562bfff-58f3-412d-a9a5-afc91ca83e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aae_dataset = pd.read_csv('2000-5000_sentences.csv')[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a16e712-7883-4e05-b45f-d9e01d8dd013",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sae_sentence = []\n",
    "processed_indices = []\n",
    "failed_indices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20ffb5eb-0eed-4ebd-97f6-9b2df2183d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [18:40<00:00,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled dataset saved to ./labeled/GPT-4o-mini-SAE.csv\n",
      "Failed indices saved to ./labeled/failed_indices_GPT-4o-mini-SAE.csv\n",
      "Number of successfully processed sentences: 2875\n",
      "Number of failed sentences: 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Process the dataset in batches of 5\n",
    "for i in tqdm(range(0, len(aae_dataset), 5)):\n",
    "    batch = aae_dataset[i:i+5].to_list()\n",
    "    batch_indices = list(range(i, min(i+5, len(aae_dataset))))\n",
    "    \n",
    "    try:\n",
    "        result = runnable.invoke({\"sentences\": \"\\n\".join(batch)})\n",
    "        \n",
    "        # Check if the number of returned sentiments matches the batch size\n",
    "        if len(result.standard_english_tweets) == len(batch):\n",
    "            all_sae_sentence.extend([response.standard_english for response in result.standard_english_tweets])\n",
    "            processed_indices.extend(batch_indices)\n",
    "        else:\n",
    "            # If the number of sentiments doesn't match, mark all as failed\n",
    "            failed_indices.extend(batch_indices)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {i}-{i+4}: {str(e)}\")\n",
    "        failed_indices.extend(batch_indices)\n",
    "\n",
    "# Create a new dataframe with successfully processed sentences and sentiments\n",
    "labeled_df = pd.DataFrame({\n",
    "    'index': processed_indices,\n",
    "    'text': aae_dataset.iloc[processed_indices],\n",
    "    'standard_american_english': all_sae_sentence\n",
    "})\n",
    "\n",
    "# Sort the dataframe by the original index\n",
    "labeled_df = labeled_df.sort_values('index').reset_index(drop=True)\n",
    "\n",
    "# Save the labeled dataset to a CSV file\n",
    "output_path = './labeled/GPT-4o-mini-SAE.csv'\n",
    "labeled_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Labeled dataset saved to {output_path}\")\n",
    "\n",
    "# Save the failed indices to a separate file\n",
    "failed_indices_path = './labeled/failed_indices_GPT-4o-mini-SAE.csv'\n",
    "pd.DataFrame({'failed_index': failed_indices}).to_csv(failed_indices_path, index=False)\n",
    "\n",
    "print(f\"Failed indices saved to {failed_indices_path}\")\n",
    "print(f\"Number of successfully processed sentences: {len(processed_indices)}\")\n",
    "print(f\"Number of failed sentences: {len(failed_indices)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf110e3e-bc5b-4503-8b6b-161b130e2274",
   "metadata": {},
   "source": [
    "## Processing the 125 failed indices with lower batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cc88517-8d40-43d2-a13a-688000575215",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:53<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete labeled dataset saved to ./labeled/complete-3000-GPT-4o-mini-SAE.csv\n",
      "Total processed sentences: 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the previously processed data\n",
    "labeled_df = pd.read_csv('./labeled/GPT-4o-mini-SAE.csv')\n",
    "labeled_df.rename(columns={\"text\" : \"african_american_english\"}, inplace=True)\n",
    "failed_indices = pd.read_csv('./labeled/failed_indices_GPT-4o-mini-SAE.csv')['failed_index'].tolist()\n",
    "\n",
    "\n",
    "new_all_sae_sentence = []\n",
    "new_processed_indices = []\n",
    "still_failed_indices = []\n",
    "\n",
    "# Process the failed sentences\n",
    "for i in tqdm(range(0, len(failed_indices), 3)):\n",
    "    batch_indices = failed_indices[i:i+3]\n",
    "    batch = aae_dataset.iloc[batch_indices].tolist()\n",
    "    \n",
    "    try:\n",
    "        result = runnable.invoke({\"sentences\": \"\\n\".join(batch)})\n",
    "        \n",
    "        \n",
    "        if len(result.standard_english_tweets) == len(batch):\n",
    "            new_all_sae_sentence.extend([response.standard_english for response in result.standard_english_tweets])\n",
    "            new_processed_indices.extend(batch_indices)\n",
    "        else:\n",
    "            # If the number of sentiments doesn't match, mark all as still failed\n",
    "            still_failed_indices.extend(batch_indices)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {i}-{i+2}: {str(e)}\")\n",
    "        still_failed_indices.extend(batch_indices)\n",
    "\n",
    "# Create a new dataframe with newly processed sentences and sentiments\n",
    "new_labeled_df = pd.DataFrame({\n",
    "    'index': new_processed_indices,\n",
    "    'african_american_english': aae_dataset.iloc[new_processed_indices],\n",
    "    'standard_american_english': new_all_sae_sentence\n",
    "})\n",
    "\n",
    "# Combine the previously processed data with the newly processed data\n",
    "combined_df = pd.concat([labeled_df, new_labeled_df], ignore_index=True)\n",
    "\n",
    "# Sort the dataframe by the original index and reset the index\n",
    "combined_df = combined_df.sort_values('index').reset_index(drop=True)\n",
    "\n",
    "# If there are still failed indices, add them to the combined dataframe with NaN sentiment\n",
    "if still_failed_indices:\n",
    "    failed_df = pd.DataFrame({\n",
    "        'index': still_failed_indices,\n",
    "        'african_american_english': aae_dataset.iloc[still_failed_indices],\n",
    "        'standard_american_english': pd.NA\n",
    "    })\n",
    "    combined_df = pd.concat([combined_df, failed_df], ignore_index=True)\n",
    "    combined_df = combined_df.sort_values('index').reset_index(drop=True)\n",
    "\n",
    "output_path = './labeled/complete-3000-GPT-4o-mini-SAE.csv'\n",
    "combined_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Complete labeled dataset saved to {output_path}\")\n",
    "print(f\"Total processed sentences: {len(combined_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77c4e8bc-81bb-41ce-b6c8-ee8a7bf76eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "falied indices: 35\n"
     ]
    }
   ],
   "source": [
    "print(f\"falied indices: {combined_df['standard_american_english'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bf18e6-f157-40cc-8112-70bb9fee835d",
   "metadata": {},
   "source": [
    "### Individually calling the API for the 35 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c50eeb6e-79f7-4d67-b74a-a3f3c8470bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardEnglish(BaseModel):\n",
    "    standard_english: str = Field(description=\"The tweet converted into Standard American English.\")\n",
    "\n",
    "\n",
    "chat_template_single = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You will be given a tweet extracted from twitter accounts belonging to African American individuals. Your task is to convert the given tweet to Standard American English.\"\"\"\n",
    "        ),\n",
    "        (\"user\", \"{sentence}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the runnable chain\n",
    "runnable_single = chat_template_single | model.with_structured_output(schema=StandardEnglish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c082b179-8cb2-4eae-82dd-a3e0ab76425b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated complete labeled dataset saved to ./labeled/complete-3000-GPT-4o-mini-SAE-FINAL.csv\n",
      "Total processed sentences: 3000\n",
      "Successfully labeled sentences: 3000\n",
      "Failed sentences: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the complete labeled dataset\n",
    "combined_df = pd.read_csv('./labeled/complete-3000-GPT-4o-mini-SAE.csv')\n",
    "\n",
    "# Apply the lambda function to process the indices where sentiment is NaN\n",
    "combined_df['standard_american_english'] = combined_df.apply(\n",
    "    lambda row: runnable_single.invoke({\"sentence\": row['african_american_english']}).standard_english\n",
    "    if pd.isna(row['standard_american_english']) else row['standard_american_english'], \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Save the updated complete labeled dataset\n",
    "output_path = './labeled/complete-3000-GPT-4o-mini-SAE-FINAL.csv'\n",
    "combined_df.to_csv(output_path, index=False)\n",
    "\n",
    "# Display the summary of the updated dataset\n",
    "updated_total = len(combined_df)\n",
    "updated_successful = combined_df['standard_american_english'].notna().sum()\n",
    "updated_failed = combined_df['standard_american_english'].isna().sum()\n",
    "\n",
    "print(f\"Updated complete labeled dataset saved to {output_path}\")\n",
    "print(f\"Total processed sentences: {updated_total}\")\n",
    "print(f\"Successfully labeled sentences: {updated_successful}\")\n",
    "print(f\"Failed sentences: {updated_failed}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d59dc61f-96d6-4d72-9e7e-b0fb944d6d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[[\"standard_american_english\", \"african_american_english\"]].to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bca31dd-64f5-41a9-a20f-21228da3e52f",
   "metadata": {},
   "source": [
    "__________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87580977-dae7-4890-83fe-467480fe4102",
   "metadata": {},
   "source": [
    "## Now getting the sentiment labels for the SAE sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cd2dd25-952e-4f32-99fd-1802a4e6992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalysisResponse(BaseModel):\n",
    "    sentiment: str = Field(description=\"The sentiment of the sentence (Positive, Negative, or Neutral)\")\n",
    "\n",
    "class Data(BaseModel):\n",
    "    \"\"\"Extracted data about sentences.\"\"\"\n",
    "    sentiments: List[SentimentAnalysisResponse]\n",
    "\n",
    "# Define the prompt template\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"Your task is to analyze the provided sentences written in Standard American English and identify the sentiment expressed by the author. The sentiment should be classified as Positive, Negative, or Neutral for each sentence.\"\"\"\n",
    "        ),\n",
    "        (\"user\", \"{sentences}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", timeout=None, max_retries=2, temperature=0)\n",
    "\n",
    "# Create the runnable chain\n",
    "sae_labels_runnable = chat_template | model.with_structured_output(schema=Data)\n",
    "\n",
    "class SentimentAnalysisResponse(BaseModel):\n",
    "    sentiment: str = Field(description=\"The sentiment of the sentence (Positive, Negative, or Neutral)\")\n",
    "\n",
    "chat_template_single = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"Your task is to analyze the provided sentence written in Standard American English and identify the sentiment expressed by the author. The sentiment should be classified as Positive, Negative, or Neutral.\"\"\"\n",
    "        ),\n",
    "        (\"user\", \"{sentences}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "sae_labels_runnable_single = chat_template_single | model.with_structured_output(schema=SentimentAnalysisResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80fe62d0-18ab-4bfd-9204-3fba751cfed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sae_sentiment = []\n",
    "processed_indices = []\n",
    "failed_indices = []\n",
    "sae_dataset = pd.read_csv('./labeled/GPT-4o-mini-SAE.csv')['standard_american_english']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "027e9ed3-e3b6-423c-94f8-c79dfccf841b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"If I don't get this job tomorrow, I don't know what I'm going to do. I'm at the end of my rope.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35f04c69-b08e-4a68-a594-4fa2e601df5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [08:09<00:00,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled dataset saved to ./labeled/GPT-4o-mini-sae-labels.csv\n",
      "Failed indices saved to ./labeled/failed_indices_GPT-4o-mini-sae-labels.csv\n",
      "Number of successfully processed sentences: 2890\n",
      "Number of failed sentences: 110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(0, len(sae_dataset), 5)):\n",
    "    batch = sae_dataset[i:i+5].to_list()\n",
    "    batch_indices = list(range(i, min(i+5, len(sae_dataset))))\n",
    "    \n",
    "    try:\n",
    "        result = sae_labels_runnable.invoke({\"sentences\": \"\\n\".join(batch)})\n",
    "        \n",
    "        if len(result.sentiments) == len(batch):\n",
    "            all_sae_sentiment.extend([response.sentiment for response in result.sentiments])\n",
    "            processed_indices.extend(batch_indices)\n",
    "        else:\n",
    "            failed_indices.extend(batch_indices)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {i}-{i+4}: {str(e)}\")\n",
    "        failed_indices.extend(batch_indices)\n",
    "\n",
    "labeled_df_sae_labels = pd.DataFrame({\n",
    "    'index': processed_indices,\n",
    "    'standard_american_english': sae_dataset.iloc[processed_indices],\n",
    "    'sae_labels': all_sae_sentiment\n",
    "})\n",
    "\n",
    "# Sort the dataframe by the original index\n",
    "labeled_df_sae_labels = labeled_df_sae_labels.sort_values('index').reset_index(drop=True)\n",
    "\n",
    "output_path = './labeled/GPT-4o-mini-sae-labels.csv'\n",
    "labeled_df_sae_labels.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Labeled dataset saved to {output_path}\")\n",
    "\n",
    "# Save the failed indices to a separate file\n",
    "failed_indices_path = './labeled/failed_indices_GPT-4o-mini-sae-labels.csv'\n",
    "pd.DataFrame({'failed_index': failed_indices}).to_csv(failed_indices_path, index=False)\n",
    "\n",
    "print(f\"Failed indices saved to {failed_indices_path}\")\n",
    "print(f\"Number of successfully processed sentences: {len(processed_indices)}\")\n",
    "print(f\"Number of failed sentences: {len(failed_indices)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54330093-61c4-4343-b1d4-7c05df03e1b4",
   "metadata": {},
   "source": [
    "## Processing the 110 failed indices with lower batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5bb1f2cc-947b-4e3d-983e-eb52a56f61ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:27<00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete labeled dataset saved to ./labeled/complete-3000-GPT-4o-mini-sae-labels.csv\n",
      "Total processed sentences: 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the previously processed data\n",
    "labeled_df = pd.read_csv('./labeled/GPT-4o-mini-sae-labels.csv')\n",
    "failed_indices = pd.read_csv('./labeled/failed_indices_GPT-4o-mini-sae-labels.csv')['failed_index'].tolist()\n",
    "\n",
    "\n",
    "new_all_sae_sentiment = []\n",
    "new_processed_indices = []\n",
    "still_failed_indices = []\n",
    "\n",
    "for i in tqdm(range(0, len(failed_indices), 2)):\n",
    "    batch_indices = failed_indices[i:i+2]\n",
    "    batch = sae_dataset.iloc[batch_indices].tolist()\n",
    "    try:\n",
    "        result = sae_labels_runnable.invoke({\"sentences\": \"\\n\".join(batch)})\n",
    "        \n",
    "        # Check if the number of returned sentiments matches the batch size\n",
    "        if len(result.sentiments) == len(batch):\n",
    "            new_all_sae_sentiment.extend([response.sentiment for response in result.sentiments])\n",
    "            new_processed_indices.extend(batch_indices)\n",
    "        else:\n",
    "            # If the number of sentiments doesn't match, mark all as still failed\n",
    "            still_failed_indices.extend(batch_indices)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {i}-{i+2}: {str(e)}\")\n",
    "        still_failed_indices.extend(batch_indices)\n",
    "\n",
    "# Create a new dataframe with newly processed sentences and sentiments\n",
    "new_labeled_df = pd.DataFrame({\n",
    "    'index': new_processed_indices,\n",
    "    'standard_american_english': sae_dataset.iloc[new_processed_indices],\n",
    "    'sae_labels': new_all_sae_sentiment\n",
    "})\n",
    "\n",
    "# Combine the previously processed data with the newly processed data\n",
    "combined_df = pd.concat([labeled_df, new_labeled_df], ignore_index=True)\n",
    "\n",
    "# Sort the dataframe by the original index and reset the index\n",
    "combined_df = combined_df.sort_values('index').reset_index(drop=True)\n",
    "\n",
    "# If there are still failed indices, add them to the combined dataframe with NaN sentiment\n",
    "if still_failed_indices:\n",
    "    failed_df = pd.DataFrame({\n",
    "        'index': still_failed_indices,\n",
    "        'standard_american_english': sae_dataset.iloc[still_failed_indices],\n",
    "        'sae_labels': pd.NA\n",
    "    })\n",
    "    combined_df = pd.concat([combined_df, failed_df], ignore_index=True)\n",
    "    combined_df = combined_df.sort_values('index').reset_index(drop=True)\n",
    "\n",
    "output_path = './labeled/complete-3000-GPT-4o-mini-sae-labels.csv'\n",
    "combined_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Complete labeled dataset saved to {output_path}\")\n",
    "print(f\"Total processed sentences: {len(combined_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e4ed5c9-dab6-44fd-8575-de67d3a1c5d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(still_failed_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f55fb4d-96b4-4d4f-a237-f3ab4f5c9ba6",
   "metadata": {},
   "source": [
    "## Calling the API individually for the 30 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a9aba456-6252-4856-a0b4-7f2feb33ec3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated complete labeled dataset saved to ./labeled/complete-3000-GPT-4o-mini-sae-labels-final.csv\n",
      "Total processed sentences: 3000\n",
      "Successfully labeled sentences: 3000\n",
      "Failed sentences: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "combined_df = pd.read_csv('./labeled/complete-3000-GPT-4o-mini-sae-labels.csv')\n",
    "\n",
    "# Apply the lambda function to process the indices where sentiment is NaN\n",
    "combined_df['sae_labels'] = combined_df.apply(\n",
    "    lambda row: sae_labels_runnable_single.invoke({\"sentences\": row['standard_american_english']}).sentiment \n",
    "    if pd.isna(row['sae_labels']) else row['sae_labels'], \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Save the updated complete labeled dataset\n",
    "output_path = './labeled/complete-3000-GPT-4o-mini-sae-labels-final.csv'\n",
    "combined_df.to_csv(output_path, index=False)\n",
    "\n",
    "# Display the summary of the updated dataset\n",
    "updated_total = len(combined_df)\n",
    "updated_successful = combined_df['sae_labels'].notna().sum()\n",
    "updated_failed = combined_df['sae_labels'].isna().sum()\n",
    "\n",
    "print(f\"Updated complete labeled dataset saved to {output_path}\")\n",
    "print(f\"Total processed sentences: {updated_total}\")\n",
    "print(f\"Successfully labeled sentences: {updated_successful}\")\n",
    "print(f\"Failed sentences: {updated_failed}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845d001a-632a-424d-a64b-65bda78133a2",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cb43a8-00a3-4bef-94ad-44cd99355a32",
   "metadata": {},
   "source": [
    "### Pipiline uptil now:\n",
    "AAE -> AAE Sentiment -> Translate to SAE -> SAE Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e666db-3642-4239-9745-e8ddd30a333e",
   "metadata": {},
   "source": [
    "## Now we go back to AAE using SAE, and finish off by obtaining sentiment on that.\n",
    "\n",
    "AAE -> AAE Sentiment -> Translate to SAE -> SAE Sentiment -> **AAE_from_SAE -> AAE_from_SAE Sentiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "92fe3b49-eca8-4a53-a3a7-94673ca0d81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardEnglish(BaseModel):\n",
    "    african_american_english: str = Field(description=\"The tweet converted into African American English.\")\n",
    "\n",
    "class Data(BaseModel):\n",
    "    \"\"\"Convert the list of SAE tweets provided to convert to African American English.\"\"\"\n",
    "    aae_from_sae_tweets: List[StandardEnglish] = Field(description=\"The list of converted tweets by order of the sentences given.\")\n",
    "\n",
    "\n",
    "aae_from_sae_chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You will be given a list of tweets in Standard American English. Your task is to convert the given tweets to African American English.\"\"\"\n",
    "        ),\n",
    "        (\"user\", \"{sentences}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", timeout=None,\n",
    "    max_retries=2, temperature=0)\n",
    "\n",
    "\n",
    "aae_from_sae_runnable = aae_from_sae_chat_template | model.with_structured_output(schema=Data)\n",
    "\n",
    "chat_template_single = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You will be given a tweet in Standard American English. Your task is to convert the given tweet to African American English.\"\"\"\n",
    "        ),\n",
    "        (\"user\", \"{sentences}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "aae_from_sae_runnable_single = chat_template_single | model.with_structured_output(schema=StandardEnglish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c8f55f34-0883-4a13-a311-6baa81773580",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_dataset = pd.read_csv('./labeled/GPT-4o-mini-SAE.csv')[\"standard_american_english\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8b711540-894e-4e5d-831f-b6acf50df13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_aae_from_sae_sentence = []\n",
    "processed_indices = []\n",
    "failed_indices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2dbd17ef-5de6-41d7-b732-610a401fe851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [22:25<00:00,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled dataset saved to ./labeled/GPT-4o-mini-AAE_from_SAE.csv\n",
      "Failed indices saved to ./labeled/failed_indices_GPT-4o-mini-AAE_from_SAE.csv\n",
      "Number of successfully processed sentences: 2980\n",
      "Number of failed sentences: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(0, len(sae_dataset), 5)):\n",
    "    batch = sae_dataset[i:i+5].to_list()\n",
    "    batch_indices = list(range(i, min(i+5, len(sae_dataset))))\n",
    "    \n",
    "    try:\n",
    "        result = aae_from_sae_runnable.invoke({\"sentences\": \"\\n\".join(batch)})\n",
    "        \n",
    "        # Check if the number of returned sentiments matches the batch size\n",
    "        if len(result.aae_from_sae_tweets) == len(batch):\n",
    "            all_aae_from_sae_sentence.extend([response.african_american_english for response in result.aae_from_sae_tweets])\n",
    "            processed_indices.extend(batch_indices)\n",
    "        else:\n",
    "            # If the number of sentiments doesn't match, mark all as failed\n",
    "            failed_indices.extend(batch_indices)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {i}-{i+4}: {str(e)}\")\n",
    "        failed_indices.extend(batch_indices)\n",
    "\n",
    "# Create a new dataframe with successfully processed sentences and sentiments\n",
    "labeled_df = pd.DataFrame({\n",
    "    'index': processed_indices,\n",
    "    'standard_american_english' : sae_dataset.iloc[processed_indices],\n",
    "    'aae_from_sae': all_aae_from_sae_sentence\n",
    "})\n",
    "\n",
    "# Sort the dataframe by the original index\n",
    "labeled_df = labeled_df.sort_values('index').reset_index(drop=True)\n",
    "\n",
    "# Save the labeled dataset to a CSV file\n",
    "output_path = './labeled/GPT-4o-mini-AAE_from_SAE.csv'\n",
    "labeled_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Labeled dataset saved to {output_path}\")\n",
    "\n",
    "# Save the failed indices to a separate file\n",
    "failed_indices_path = './labeled/failed_indices_GPT-4o-mini-AAE_from_SAE.csv'\n",
    "pd.DataFrame({'failed_index': failed_indices}).to_csv(failed_indices_path, index=False)\n",
    "\n",
    "print(f\"Failed indices saved to {failed_indices_path}\")\n",
    "print(f\"Number of successfully processed sentences: {len(processed_indices)}\")\n",
    "print(f\"Number of failed sentences: {len(failed_indices)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9181983f-6853-4ea9-9045-ac0977604118",
   "metadata": {},
   "source": [
    "## Calling the API with lower batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "98ffa864-3484-43d6-9bb3-968297324dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete GPT-4o-mini-AAE_from_SAE dataset saved to ./labeled/complete-3000-GPT-4o-mini-AAE_from_SAE.csv\n",
      "Total processed sentences: 3000\n",
      "Still Failed sentences: 2\n"
     ]
    }
   ],
   "source": [
    "# # Load the previously processed data\n",
    "labeled_df = pd.read_csv('./labeled/GPT-4o-mini-AAE_from_SAE.csv')\n",
    "failed_indices = pd.read_csv('./labeled/failed_indices_GPT-4o-mini-AAE_from_SAE.csv')['failed_index'].tolist()\n",
    "\n",
    "\n",
    "new_aae_from_sae_sentence = []\n",
    "new_processed_indices = []\n",
    "still_failed_indices = []\n",
    "\n",
    "for i in tqdm(range(0, len(failed_indices), 2)):\n",
    "    batch_indices = failed_indices[i:i+2]\n",
    "    batch = sae_dataset.iloc[batch_indices].tolist()\n",
    "    try:\n",
    "        result = aae_from_sae_runnable.invoke({\"sentences\": \"\\n\".join(batch)})\n",
    "        \n",
    "        # Check if the number of returned sentiments matches the batch size\n",
    "        if len(result.aae_from_sae_tweets) == len(batch):\n",
    "            new_aae_from_sae_sentence.extend([response.african_american_english for response in result.aae_from_sae_tweets])\n",
    "            new_processed_indices.extend(batch_indices)\n",
    "        else:\n",
    "            # If the number of sentiments doesn't match, mark all as failed\n",
    "            still_failed_indices.extend(batch_indices)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {i}-{i+2}: {str(e)}\")\n",
    "        still_failed_indices.extend(batch_indices)\n",
    "\n",
    "# Create a new dataframe with newly processed sentences and sentiments\n",
    "new_labeled_df = pd.DataFrame({\n",
    "    'index': new_processed_indices,\n",
    "    'standard_american_english': sae_dataset.iloc[new_processed_indices],\n",
    "    'aae_from_sae': new_aae_from_sae_sentence\n",
    "})\n",
    "\n",
    "# Combine the previously processed data with the newly processed data\n",
    "combined_df = pd.concat([labeled_df, new_labeled_df], ignore_index=True)\n",
    "\n",
    "# Sort the dataframe by the original index and reset the index\n",
    "combined_df = combined_df.sort_values('index').reset_index(drop=True)\n",
    "\n",
    "# If there are still failed indices, add them to the combined dataframe with NaN sentiment\n",
    "if still_failed_indices:\n",
    "    failed_df = pd.DataFrame({\n",
    "        'index': still_failed_indices,\n",
    "        'standard_american_english': sae_dataset.iloc[still_failed_indices],\n",
    "        'sae_labels': pd.NA\n",
    "    })\n",
    "    combined_df = pd.concat([combined_df, failed_df], ignore_index=True)\n",
    "    combined_df = combined_df.sort_values('index').reset_index(drop=True)\n",
    "\n",
    "output_path = './labeled/complete-3000-GPT-4o-mini-AAE_from_SAE.csv'\n",
    "combined_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Complete GPT-4o-mini-AAE_from_SAE dataset saved to {output_path}\")\n",
    "print(f\"Total processed sentences: {len(combined_df)}\")\n",
    "print(f\"Still Failed sentences: {len(still_failed_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c682e868-a08f-4d18-a1d1-5c87f244fab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated complete labeled dataset saved to ./labeled/GPT-4o-mini-AAE_from_SAE-FINAL.csv\n",
      "Total processed sentences: 3000\n",
      "Successfully labeled sentences: 3000\n",
      "Failed sentences: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "combined_df = pd.read_csv('./labeled/complete-3000-GPT-4o-mini-AAE_from_SAE.csv')\n",
    "\n",
    "# Apply the lambda function to process the indices where sentiment is NaN\n",
    "combined_df['aae_from_sae'] = combined_df.apply(\n",
    "    lambda row: aae_from_sae_runnable_single.invoke({\"sentences\": row['standard_american_english']}).african_american_english\n",
    "    if pd.isna(row['aae_from_sae']) else row['aae_from_sae'], \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Save the updated complete labeled dataset\n",
    "output_path = './labeled/GPT-4o-mini-AAE_from_SAE-FINAL.csv'\n",
    "combined_df[[\"aae_from_sae\", \"standard_american_english\"]].to_csv(output_path, index=False)\n",
    "\n",
    "# Display the summary of the updated dataset\n",
    "updated_total = len(combined_df)\n",
    "updated_successful = combined_df['aae_from_sae'].notna().sum()\n",
    "updated_failed = combined_df['aae_from_sae'].isna().sum()\n",
    "\n",
    "print(f\"Updated complete labeled dataset saved to {output_path}\")\n",
    "print(f\"Total processed sentences: {updated_total}\")\n",
    "print(f\"Successfully labeled sentences: {updated_successful}\")\n",
    "print(f\"Failed sentences: {updated_failed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b21a62-a894-47b9-a46b-36f13b1f08a2",
   "metadata": {},
   "source": [
    "## Getting the sentiment for AAE_from_SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "787ccd66-d4f4-4992-ab66-43f04a2d3e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema for sentiment analysis\n",
    "class SentimentAnalysisResponse(BaseModel):\n",
    "    sentiment: str = Field(description=\"The sentiment of the sentence (Positive, Negative, or Neutral)\")\n",
    "\n",
    "class Data(BaseModel):\n",
    "    \"\"\"Extracted data about sentences.\"\"\"\n",
    "    sentiments: List[SentimentAnalysisResponse]\n",
    "\n",
    "# Define the prompt template\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"Your task is to analyze the provided sentences written in African American English and identify the sentiment expressed by the author. \n",
    "            The sentiment should be classified as Positive, Negative, or Neutral for each sentence.\"\"\"\n",
    "        ),\n",
    "        (\"user\", \"{sentences}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the language model\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Create the runnable chain\n",
    "runnable = chat_template | model.with_structured_output(schema=Data)\n",
    "\n",
    "single_chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"Your task is to analyze the provided sentence written in African American English and identify the sentiment expressed by the author. \n",
    "            The sentiment should be classified as Positive, Negative, or Neutral for each sentence.\"\"\"\n",
    "        ),\n",
    "        (\"user\", \"{sentences}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "runnable_single = single_chat_template | model.with_structured_output(schema=SentimentAnalysisResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "107fb063-a2a5-4bb5-b09f-6f1f0401ab1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./labeled/GPT-4o-mini-AAE_from_SAE.csv\")[\"aae_from_sae\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "22fdfc79-e4e5-4689-940b-b9a0c053bcc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [06:39<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled dataset saved to ./labeled/GPT-4o-mini-AAE_from_SAE_labels.csv\n",
      "Failed indices saved to ./labeled/GPT-4o-mini-AAE_from_SAE_labels_failed_indices.csv\n",
      "Number of successfully processed sentences: 2915\n",
      "Number of failed sentences: 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store the sentiments and their corresponding indices\n",
    "all_sentiments = []\n",
    "processed_indices = []\n",
    "failed_indices = []\n",
    "\n",
    "# Process the dataset in batches of 5\n",
    "for i in tqdm(range(0, len(dataset), 5)):\n",
    "    batch = dataset[i:i+5].to_list()\n",
    "    batch_indices = list(range(i, min(i+5, len(dataset))))\n",
    "    \n",
    "    try:\n",
    "        result = runnable.invoke({\"sentences\": \"\\n\".join(batch)})\n",
    "        \n",
    "        # Check if the number of returned sentiments matches the batch size\n",
    "        if len(result.sentiments) == len(batch):\n",
    "            all_sentiments.extend([response.sentiment for response in result.sentiments])\n",
    "            processed_indices.extend(batch_indices)\n",
    "        else:\n",
    "            # If the number of sentiments doesn't match, mark all as failed\n",
    "            failed_indices.extend(batch_indices)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {i}-{i+4}: {str(e)}\")\n",
    "        failed_indices.extend(batch_indices)\n",
    "\n",
    "# Create a new dataframe with successfully processed sentences and sentiments\n",
    "labeled_df = pd.DataFrame({\n",
    "    'index': processed_indices,\n",
    "    'aae_from_sae': dataset.iloc[processed_indices],\n",
    "    'sentiment': all_sentiments\n",
    "})\n",
    "\n",
    "# Sort the dataframe by the original index\n",
    "labeled_df = labeled_df.sort_values('index').reset_index(drop=True)\n",
    "\n",
    "# Save the labeled dataset to a CSV file\n",
    "output_path = './labeled/GPT-4o-mini-AAE_from_SAE_labels.csv'\n",
    "labeled_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Labeled dataset saved to {output_path}\")\n",
    "\n",
    "# Save the failed indices to a separate file\n",
    "failed_indices_path = './labeled/GPT-4o-mini-AAE_from_SAE_labels_failed_indices.csv'\n",
    "pd.DataFrame({'failed_index': failed_indices}).to_csv(failed_indices_path, index=False)\n",
    "\n",
    "print(f\"Failed indices saved to {failed_indices_path}\")\n",
    "print(f\"Number of successfully processed sentences: {len(processed_indices)}\")\n",
    "print(f\"Number of failed sentences: {len(failed_indices)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb9935a-1d3e-4ce7-ba90-0f70ddb4d042",
   "metadata": {},
   "source": [
    "## Processing the failed 85 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "18ac8157-397c-4258-bd68-0174f30ef93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:16<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete labeled dataset saved to ./labeled/complete-3000-GPT-4o-mini-AAE_from_SAE_labels.csv\n",
      "Total processed sentences: 3000\n",
      "Successfully labeled sentences: 2997\n",
      "Failed sentences: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the previously processed data\n",
    "labeled_df = pd.read_csv('./labeled/GPT-4o-mini-AAE_from_SAE_labels.csv')\n",
    "failed_indices = pd.read_csv('./labeled/GPT-4o-mini-AAE_from_SAE_labels_failed_indices.csv')['failed_index'].tolist()\n",
    "\n",
    "\n",
    "# Initialize lists to store the new sentiments and their corresponding indices\n",
    "new_sentiments = []\n",
    "new_processed_indices = []\n",
    "still_failed_indices = []\n",
    "\n",
    "# Process the failed sentences\n",
    "for i in tqdm(range(0, len(failed_indices), 3)):\n",
    "    batch_indices = failed_indices[i:i+3]\n",
    "    batch = dataset.iloc[batch_indices].tolist()\n",
    "    \n",
    "    try:\n",
    "        result = runnable.invoke({\"sentences\": \"\\n\".join(batch)})\n",
    "        \n",
    "        # Check if the number of returned sentiments matches the batch size\n",
    "        if len(result.sentiments) == len(batch):\n",
    "            new_sentiments.extend([response.sentiment for response in result.sentiments])\n",
    "            new_processed_indices.extend(batch_indices)\n",
    "        else:\n",
    "            # If the number of sentiments doesn't match, mark all as still failed\n",
    "            still_failed_indices.extend(batch_indices)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {i}-{i+2}: {str(e)}\")\n",
    "        still_failed_indices.extend(batch_indices)\n",
    "\n",
    "# Create a new dataframe with newly processed sentences and sentiments\n",
    "new_labeled_df = pd.DataFrame({\n",
    "    'index': new_processed_indices,\n",
    "    'aae_from_sae': dataset.iloc[new_processed_indices],\n",
    "    'sentiment': new_sentiments\n",
    "})\n",
    "\n",
    "# Combine the previously processed data with the newly processed data\n",
    "combined_df = pd.concat([labeled_df, new_labeled_df], ignore_index=True)\n",
    "\n",
    "# Sort the dataframe by the original index and reset the index\n",
    "combined_df = combined_df.sort_values('index').reset_index(drop=True)\n",
    "\n",
    "# If there are still failed indices, add them to the combined dataframe with NaN sentiment\n",
    "if still_failed_indices:\n",
    "    failed_df = pd.DataFrame({\n",
    "        'index': still_failed_indices,\n",
    "        'aae_from_sae': dataset.iloc[still_failed_indices],\n",
    "        'sentiment': pd.NA\n",
    "    })\n",
    "    combined_df = pd.concat([combined_df, failed_df], ignore_index=True)\n",
    "    combined_df = combined_df.sort_values('index').reset_index(drop=True)\n",
    "\n",
    "# Save the complete labeled dataset to a CSV file\n",
    "output_path = './labeled/complete-3000-GPT-4o-mini-AAE_from_SAE_labels.csv'\n",
    "combined_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Complete labeled dataset saved to {output_path}\")\n",
    "print(f\"Total processed sentences: {len(combined_df)}\")\n",
    "print(f\"Successfully labeled sentences: {combined_df['sentiment'].notna().sum()}\")\n",
    "print(f\"Failed sentences: {combined_df['sentiment'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bdabf031-c7a6-4bf8-97f1-8c1aa4ef7a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated complete labeled dataset saved to ./labeled/complete-3000-GPT-4o-mini-AAE_from_SAE_labels-final.csv\n",
      "Total processed sentences: 3000\n",
      "Successfully labeled sentences: 3000\n",
      "Failed sentences: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "combined_df = pd.read_csv('./labeled/complete-3000-GPT-4o-mini-AAE_from_SAE_labels.csv')\n",
    "\n",
    "# Apply the lambda function to process the indices where sentiment is NaN\n",
    "combined_df['sentiment'] = combined_df.apply(\n",
    "    lambda row: runnable_single.invoke({\"sentences\": row['aae_from_sae']}).sentiment \n",
    "    if pd.isna(row['sentiment']) else row['sentiment'], \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Save the updated complete labeled dataset\n",
    "output_path = './labeled/complete-3000-GPT-4o-mini-AAE_from_SAE_labels-final.csv'\n",
    "combined_df.to_csv(output_path, index=False)\n",
    "\n",
    "# Display the summary of the updated dataset\n",
    "updated_total = len(combined_df)\n",
    "updated_successful = combined_df['sentiment'].notna().sum()\n",
    "updated_failed = combined_df['sentiment'].isna().sum()\n",
    "\n",
    "print(f\"Updated complete labeled dataset saved to {output_path}\")\n",
    "print(f\"Total processed sentences: {updated_total}\")\n",
    "print(f\"Successfully labeled sentences: {updated_successful}\")\n",
    "print(f\"Failed sentences: {updated_failed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776be437-af49-4287-910e-d374c29f2e42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "augment",
   "language": "python",
   "name": "augmentation-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
