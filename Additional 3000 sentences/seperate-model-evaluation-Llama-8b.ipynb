{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02a9c506-1f0d-4e95-adae-c9ee4bdcdf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_token = \"huggingface-token-here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "548cfa76-f87f-4ff6-b716-2bf855deb671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a272085ff8647a6b690602d734f2d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21864ae9-30ce-4356-80af-f662891a5073",
   "metadata": {},
   "source": [
    "## LLAMA3.1 8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d8855fd-05fb-4aae-b505-40813245f6a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f39c64742434415b179ad42d0d5049d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/furquanh/miniconda3/envs/augmentation-project/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/local/home/furquanh/miniconda3/envs/augmentation-project/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrrr, ye landlubber! I be Captain Chatbeard, the scurvy dog o' the seven seas... er, the internet! Me and me trusty keyboard be here to swab the decks o' yer questions and provide ye with the treasure o' knowledge ye seek! So hoist the sails and set course fer a swashbucklin' good time, matey!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "cache_dir = \"../cache\"\n",
    "os.environ['TRANSFORMERS_CACHE'] = cache_dir\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"cuda:1\", \n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    cache_dir=cache_dir, \n",
    "    token=hf_token\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "     max_new_tokens=100, do_sample=False, num_return_sequences=1, return_full_text=False, pad_token_id=128009\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    messages,\n",
    "    max_new_tokens=156,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdaf025d-b9c8-41c5-acf1-ea67c695a6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128009"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4e015bd-3c6a-4af2-9bb9-a959829cf2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Arrrr, ye landlubber! I be'}]\n"
     ]
    }
   ],
   "source": [
    "print(pipeline(messages, max_new_tokens=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdd5cdb2-d5e5-489c-a917-91c651f3f7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract sentiment from model output\n",
    "def extract_sentiment(output):\n",
    "    if \"Positive\" in output:\n",
    "        return \"Positive\"\n",
    "    elif \"Negative\" in output:\n",
    "        return \"Negative\"\n",
    "    elif \"Neutral\" in output:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "\n",
    "def generate_sentiment(examples):\n",
    "    outputs =  pipeline(\n",
    "       examples['prompt'],\n",
    "        max_new_tokens=5,\n",
    "                do_sample=False,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    return {\"sentiment\": [output[0][\"generated_text\"] for output in outputs]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c84888e1-954c-437f-8c3f-4a4b42a8e97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b7c068426146fbb03a864218cb015c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function generate_sentiment at 0x7fbc447a1820> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78e046599b8d42ed8b66baa0a0066e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/furquanh/miniconda3/envs/augmentation-project/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/local/home/furquanh/miniconda3/envs/augmentation-project/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully generated models answers\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "\n",
    "datasets.logging.set_verbosity_info()\n",
    "\n",
    "# Function to create prompts for sentiment analysis\n",
    "def create_prompt(example):\n",
    "    return  [\n",
    "    {\"role\": \"system\", \"content\": \"Following is a tweet extracted from an African American individual's twitter account. Identify the sentiment expressed by the author of the tweet. The sentiment must be classified as either of Positive, Negative, or Neutral.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{example['text']}\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The sentiment expressed in this sentence is: \"}\n",
    "]\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('./seperate models/5000_AAE_sentence.csv')[[\"text\"]]\n",
    "\n",
    "\n",
    "# Create a Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Add prompts to the dataset\n",
    "\n",
    "dataset = dataset.map(lambda example: {\"prompt\": create_prompt(example)})\n",
    "\n",
    "# Generate sentiments\n",
    "dataset = dataset.map(\n",
    "    generate_sentiment,\n",
    "    batched=True,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(\"successfully generated models answers\")\n",
    "\n",
    "# Convert back to pandas DataFrame\n",
    "labeled_df = dataset.to_pandas()\n",
    "\n",
    "# # Save the labeled dataset to a CSV file\n",
    "output_path = './seperate models/LLama3.1-8b-AAE-Labels-FINAL.csv'\n",
    "labeled_df[[\"text\", \"sentiment\"]].to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "c86178f9-6e0e-4c48-8d36-70b69b5125d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "aae_sentiment = pd.read_csv('./seperate models/LLama3.1-8b-AAE-Labels-FINAL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "7bbfc681-3001-4531-977a-5cbdaba63e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "harmful_removed = aae_sentiment.loc[~sae_labels.index.isin([50, 77, 690, 817, 1010, 1775, 1846, 2941])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "85c1e046-4325-463e-951f-98cef529fbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "harmful_removed.to_csv('./seperate models/llama-some-removed/LLama3.1-8b-AAE-Labels-FINAL.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e849c75-522e-4e47-823f-b4989c9c1e1e",
   "metadata": {},
   "source": [
    "____________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bcbb6ac-2c57-4be0-bff0-c51066e5b4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f34eabee-74f6-4b22-b158-51122bbdf2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./seperate models/5000_AAE_sentence.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48069f88-e539-4a98-bae5-1c5d0ae2a0f0",
   "metadata": {},
   "source": [
    "## Translation to SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3755a02a-7966-4b6d-bc21-2b29249a12cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "441820c0a6fb4b7b993437e121c91d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function generate_sae at 0x7fbe617f6ee0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee477a1d05d84a25bb3f592dd0bad993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/furquanh/miniconda3/envs/augmentation-project/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/local/home/furquanh/miniconda3/envs/augmentation-project/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully generated models answers\n",
      "SAE dataset saved to ./seperate models/Llama-3.1-SAE.csv\n",
      "Number of processed sentences: 5000\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "datasets.logging.set_verbosity_info()\n",
    "\n",
    "# Function to create prompts for sentiment analysis\n",
    "def create_prompt(example):\n",
    "    return  [\n",
    "    {\"role\": \"system\", \"content\": \"Following is a tweet extracted from a African American twitter individual's account. Your task is to convert the tweet to Standard American English. Reply with just the sentence.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{example['text']}\"}\n",
    "]\n",
    "\n",
    "# Create a Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Add prompts to the dataset\n",
    "dataset = dataset.map(lambda example: {\"prompt\": create_prompt(example)})\n",
    "\n",
    "# Function to generate sentiments\n",
    "def generate_sae(examples):\n",
    "    outputs = pipeline(\n",
    "      examples[\"prompt\"],\n",
    "        max_new_tokens=100,\n",
    "                do_sample=False,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    return {\"standard_american_english\": [output[0][\"generated_text\"] for output in outputs]}\n",
    "\n",
    "# Generate sentiments\n",
    "dataset = dataset.map(\n",
    "    generate_sae,\n",
    "    batched=True,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(\"successfully generated models answers\")\n",
    "\n",
    "# Convert back to pandas DataFrame\n",
    "labeled_df = dataset.to_pandas()\n",
    "\n",
    "# Save the labeled dataset to a CSV file\n",
    "output_path = './seperate models/Llama-3.1-SAE.csv'\n",
    "labeled_df[[\"text\", \"standard_american_english\"]].rename(columns={\"text\": \"african_american_english\"}).to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"SAE dataset saved to {output_path}\")\n",
    "print(f\"Number of processed sentences: {len(labeled_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "f3ea9294-5197-43c2-9110-06e50d75695e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aae_to_sae = pd.read_csv('./seperate models/Llama-3.1-SAE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "dfd62185-6572-4c89-bbd8-612025d178c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sae_labels = pd.read_csv('./seperate models/Llama-3.1-SAE-sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "739576d8-a0c9-4799-9ed5-ec3de857854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sae_labels['sae_labels'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "031af19c-c5b4-4ba8-8df0-ff4ce0bec606",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sae_labels.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "0abb9db8-cb26-4d2b-a0c6-812ecd129c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#i_cant_assist = sae_labels.iloc[[50, 77, 690, 817, 1010, 1846, 2941]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "f556a38f-8086-483c-bcaf-15bc52bf16f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#i_cant_assist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "214e5bc7-9d87-42a8-9663-c1b4ca2c2cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_df = aae_to_sae.loc[~aae_to_sae.index.isin([50, 77, 690, 817, 1775, 1010, 1846, 2941])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "60ecd2d6-305e-4a6d-aa92-0eeead087ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_df.to_csv('./seperate models/llama-some-removed/Llama-3.1-SAE.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "aa43fe73-c6ed-439c-b2f5-ac51a0849707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4992, 2)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea8773c4-8f7a-49f7-8820-db0248cbbbb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>prompt</th>\n",
       "      <th>standard_american_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bitch cant get shit from me but bubble gum nd ...</td>\n",
       "      <td>[{'content': 'Following is a tweet extracted f...</td>\n",
       "      <td>This woman can't get anything from me, but she...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@islandboi_B yes that's what's up. Nothin like...</td>\n",
       "      <td>[{'content': 'Following is a tweet extracted f...</td>\n",
       "      <td>@islandboi_B, yes that's what's going on. Ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mixed huh !? Those black ass knees and elbows ...</td>\n",
       "      <td>[{'content': 'Following is a tweet extracted f...</td>\n",
       "      <td>Mixed huh!? Those black knees and elbows will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The bul Mike James from @mavs ain't shit n he ...</td>\n",
       "      <td>[{'content': 'Following is a tweet extracted f...</td>\n",
       "      <td>Mike James from the Mavericks is completely us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It took for a whole stranger to tell me he PRO...</td>\n",
       "      <td>[{'content': 'Following is a tweet extracted f...</td>\n",
       "      <td>It took a complete stranger to tell me how pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Bitch cant get shit from me but bubble gum nd ...   \n",
       "1  @islandboi_B yes that's what's up. Nothin like...   \n",
       "2  Mixed huh !? Those black ass knees and elbows ...   \n",
       "3  The bul Mike James from @mavs ain't shit n he ...   \n",
       "4  It took for a whole stranger to tell me he PRO...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  [{'content': 'Following is a tweet extracted f...   \n",
       "1  [{'content': 'Following is a tweet extracted f...   \n",
       "2  [{'content': 'Following is a tweet extracted f...   \n",
       "3  [{'content': 'Following is a tweet extracted f...   \n",
       "4  [{'content': 'Following is a tweet extracted f...   \n",
       "\n",
       "                           standard_american_english  \n",
       "0  This woman can't get anything from me, but she...  \n",
       "1  @islandboi_B, yes that's what's going on. Ther...  \n",
       "2  Mixed huh!? Those black knees and elbows will ...  \n",
       "3  Mike James from the Mavericks is completely us...  \n",
       "4  It took a complete stranger to tell me how pro...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc54cc6-643a-4639-9c16-5df445708e65",
   "metadata": {},
   "source": [
    "# Getting labels for SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62bea4c8-9d18-4b6a-a5e8-c871de4bc28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./seperate models/Llama-3.1-SAE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a27bfbd0-7ce2-4d4f-817e-3616c5680323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ad9467334c4425fa0fefbe3de308f36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function generate_sae_labels at 0x7fbc447a1af0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a99cce60929043a481dc7dfc598d2d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/furquanh/miniconda3/envs/augmentation-project/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/local/home/furquanh/miniconda3/envs/augmentation-project/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully generated models answers\n",
      "SAE dataset saved to ./seperate models/Llama-3.1-SAE-sentiment.csv\n",
      "Number of processed sentences: 5000\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "datasets.logging.set_verbosity_info()\n",
    "\n",
    "\n",
    "# Function to create prompts for sentiment analysis\n",
    "def create_prompt(example):\n",
    "    return  [\n",
    "    {\"role\": \"system\", \"content\": \"Your task is to analyze the provided sentences written in Standard American English and identify the sentiment expressed by the author. Reply back in one word with just the sentiment, Positive, Negative, or Neutral only\\n\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{example['standard_american_english']}\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The sentiment expressed in this sentence is: \"}\n",
    "]\n",
    "\n",
    "# Create a Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Add prompts to the dataset\n",
    "dataset = dataset.map(lambda example: {\"prompt\": create_prompt(example)})\n",
    "\n",
    "def extract_sentiment(response):\n",
    "    if \"Positive\" in response:\n",
    "        return \"Positive\"\n",
    "    elif \"Negative\"  in response:\n",
    "        return \"Negative\"\n",
    "    elif \"Neutral\" in response:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# Function to generate sentiments\n",
    "def generate_sae_labels(examples):\n",
    "    outputs = pipeline(\n",
    "      examples[\"prompt\"],\n",
    "         max_new_tokens=5,\n",
    "                do_sample=False,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    return {\"sae_labels\": [extract_sentiment(output[0][\"generated_text\"]) for output in outputs],\n",
    "           \"model_generation\" : [output[0][\"generated_text\"] for output in outputs]}\n",
    "\n",
    "# Generate sentiments\n",
    "dataset = dataset.map(\n",
    "    generate_sae_labels,\n",
    "    batched=True,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(\"successfully generated models answers\")\n",
    "\n",
    "# Convert back to pandas DataFrame\n",
    "labeled_df = dataset.to_pandas()\n",
    "\n",
    "output_path = './seperate models/Llama-3.1-SAE-sentiment.csv'\n",
    "labeled_df[[\"standard_american_english\", \"sae_labels\", \"model_generation\"]].to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"SAE dataset saved to {output_path}\")\n",
    "print(f\"Number of processed sentences: {len(labeled_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7354bbfe-fc76-4cef-8241-05e00d9a412c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown = labeled_df[labeled_df[\"sae_labels\"] == 'Unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76b86aed-3a53-43ec-9a0f-7afa37fc5033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>african_american_english</th>\n",
       "      <th>standard_american_english</th>\n",
       "      <th>prompt</th>\n",
       "      <th>sae_labels</th>\n",
       "      <th>model_generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>So at 2PM I was super tired. Now at almost 1AM...</td>\n",
       "      <td>I was extremely exhausted at 2 PM, but now at ...</td>\n",
       "      <td>[{'content': 'Your task is to analyze the prov...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Confused</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Thank you Lord for waking me up this morning ....</td>\n",
       "      <td>Thank you, Lord, for waking me up this morning...</td>\n",
       "      <td>[{'content': 'Your task is to analyze the prov...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>I feel like he dont even want to talk to me,  ...</td>\n",
       "      <td>I feel like he doesn't even want to talk to me...</td>\n",
       "      <td>[{'content': 'Your task is to analyze the prov...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>Back in the days when I was young um not a kid...</td>\n",
       "      <td>When I was younger, I sometimes find myself si...</td>\n",
       "      <td>[{'content': 'Your task is to analyze the prov...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Nostalgic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>Sometimes I wish I could rewind back to the su...</td>\n",
       "      <td>Sometimes I wish I could rewind back to the su...</td>\n",
       "      <td>[{'content': 'Your task is to analyze the prov...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Nostalgic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               african_american_english  \\\n",
       "63    So at 2PM I was super tired. Now at almost 1AM...   \n",
       "159   Thank you Lord for waking me up this morning ....   \n",
       "985   I feel like he dont even want to talk to me,  ...   \n",
       "993   Back in the days when I was young um not a kid...   \n",
       "2498  Sometimes I wish I could rewind back to the su...   \n",
       "\n",
       "                              standard_american_english  \\\n",
       "63    I was extremely exhausted at 2 PM, but now at ...   \n",
       "159   Thank you, Lord, for waking me up this morning...   \n",
       "985   I feel like he doesn't even want to talk to me...   \n",
       "993   When I was younger, I sometimes find myself si...   \n",
       "2498  Sometimes I wish I could rewind back to the su...   \n",
       "\n",
       "                                                 prompt sae_labels  \\\n",
       "63    [{'content': 'Your task is to analyze the prov...    Unknown   \n",
       "159   [{'content': 'Your task is to analyze the prov...    Unknown   \n",
       "985   [{'content': 'Your task is to analyze the prov...    Unknown   \n",
       "993   [{'content': 'Your task is to analyze the prov...    Unknown   \n",
       "2498  [{'content': 'Your task is to analyze the prov...    Unknown   \n",
       "\n",
       "     model_generation  \n",
       "63           Confused  \n",
       "159             Mixed  \n",
       "985             Mixed  \n",
       "993         Nostalgic  \n",
       "2498        Nostalgic  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc7097fc-92e5-41e1-9dc8-5efc7d9038cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sae_sentiment = pd.read_csv('./seperate models/Llama-3.1-SAE-sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b053f4af-b94c-46ea-8f57-ceeadc601989",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_sentiment = sae_sentiment.loc[~sae_sentiment.index.isin([50, 77, 690, 817, 1775, 1010, 1846, 2941])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a428452-b250-4594-9293-52b95cb16948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4992, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae_sentiment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1973ff62-34f7-4efd-ac9a-eff1b965771f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_sentiment.to_csv('./seperate models/some-removed/Llama-3.1-SAE-sentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9c4d54-f4f7-4001-80e6-d7cccf1696e8",
   "metadata": {},
   "source": [
    "### changing the prompt, adding \"No other words allowed in sentiment other than 'Positive', 'Negative' or 'Neutral'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4be7c08b-0778-4bf8-ab63-425e660b1110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract sentiment from model output\n",
    "def extract_sentiment(response):\n",
    "    if \"Positive\" in response:\n",
    "        return \"Positive\"\n",
    "    elif \"Negative\" in response:\n",
    "        return \"Negative\"\n",
    "    elif \"Neutral\" in response:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "    \n",
    "    \n",
    "def generate_sentiment(sentence):\n",
    "    outputs = pipeline(\n",
    "        [\n",
    "    {\"role\": \"system\", \"content\": \"Your task is to analyze the provided sentences written in Standard American English and identify the sentiment expressed by the author. The sentiment should be one of Positive, Negative, or Neutral. No other words are allowed in your answer.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{sentence}\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The sentiment expressed in this sentence is: \"}\n",
    "],\n",
    "        max_new_tokens=5,\n",
    "        do_sample=False,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    return extract_sentiment(outputs[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f95e0cea-6859-45c1-9f5a-994c7d93c7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process a single row\n",
    "def process_row_sentiment(row):\n",
    "    return generate_sentiment(row[\"standard_american_english\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d86608b9-b572-484c-8c3b-4115c0101276",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = labeled_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1cdbcb36-6b00-42d7-ab0c-0672b82a754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ~labeled_df[\"sae_labels\"].isin([\"Positive\", \"Negative\", \"Neutral\"])\n",
    "test.loc[mask, \"sae_labels\"] = labeled_df[mask].apply(process_row_sentiment, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d49625df-2a1d-442f-9354-37ef2c5b0d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown = test[test[\"sae_labels\"] == 'Unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b76e0caf-cc87-41e3-a2b5-290045d39d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>african_american_english</th>\n",
       "      <th>standard_american_english</th>\n",
       "      <th>prompt</th>\n",
       "      <th>sae_labels</th>\n",
       "      <th>model_generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [african_american_english, standard_american_english, prompt, sae_labels, model_generation]\n",
       "Index: []"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d5cd7d20-5bee-48df-996a-e6ef5f8e8c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[[\"standard_american_english\", \"sae_labels\"]].to_csv(\"./seperate models/Llama-3.1-SAE-sentiment.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bb63b8-5723-4a75-ac74-70af33d9fce5",
   "metadata": {},
   "source": [
    "## Back to AAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "079e9cee-c5e2-4566-a3d5-de069780f7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./seperate models/Llama-3.1-SAE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "30da99a5-aaf0-475c-bfb8-d10cf9580d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "datasets.logging.set_verbosity_info()\n",
    "\n",
    "# Function to create prompts for sentiment analysis\n",
    "def create_aae_from_sae_prompt(example):\n",
    "    return  [\n",
    "    {\"role\": \"system\", \"content\": \"You will be given a tweet in Standard American English. Your task is to convert the given tweet to African American English. Reply with just the translated sentence.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{example['standard_american_english']}\"}\n",
    "]\n",
    "\n",
    "# Create a Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Add prompts to the dataset\n",
    "dataset = dataset.map(lambda example: {\"prompt\": create_aae_from_sae_prompt(example)})\n",
    "\n",
    "# Function to generate sentiments\n",
    "def generate_aae_from_sae(examples):\n",
    "    outputs = pipeline(\n",
    "      examples[\"prompt\"],\n",
    "        max_new_tokens=100,\n",
    "        do_sample=False,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    return {\"AAE_from_SAE\": [output[0][\"generated_text\"] for output in outputs]}\n",
    "\n",
    "# Generate sentiments\n",
    "dataset = dataset.map(\n",
    "    generate_aae_from_sae,\n",
    "    batched=True,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(\"successfully generated models answers\")\n",
    "\n",
    "# Convert back to pandas DataFrame\n",
    "labeled_df = dataset.to_pandas()\n",
    "\n",
    "output_path = './seperate models/Llama-3.1-AAE_from_SAE.csv'\n",
    "labeled_df[[\"standard_american_english\", \"AAE_from_SAE\"]].to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "2dac6904-0604-41b3-a791-880abd6640d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "aae_from_sae = pd.read_csv('./seperate models/Llama-3.1-AAE_from_SAE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "aa5e8a19-91f7-4f78-9ddf-ea4a70e5c59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aae_from_sae = aae_from_sae.loc[~aae_from_sae.index.isin([50, 77, 690, 817, 1775, 1010, 1846, 2941])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "108dae0d-d804-4773-b864-c520e3a4e547",
   "metadata": {},
   "outputs": [],
   "source": [
    "aae_from_sae.to_csv('./seperate models/llama-some-removed/Llama-3.1-AAE_from_SAE.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "00846ad3-057f-4ef0-bcd7-e2cdcff1e42b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4992, 2)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aae_from_sae.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40854b08-bb85-405c-9842-c76fd44c2bde",
   "metadata": {},
   "source": [
    "## AAE_from_SAE labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "735f1f01-0e90-4f20-83bf-2dad32789161",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./seperate models/Llama-3.1-AAE_from_SAE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "3fa1fab4-86e9-4b69-875e-931e6ce543f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully generated models answers\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "datasets.logging.set_verbosity_info()\n",
    "\n",
    "# Function to create prompts for sentiment analysis\n",
    "def create_aae_from_sae_prompt(example):\n",
    "    return  [\n",
    "    {\"role\": \"system\", \"content\": \"Your task is to analyze the provided sentences written in African American English and identify the sentiment expressed by the author. The sentiment must be classified as Positive, Negative, or Neutral. Reply with just the sentiment.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{example['AAE_from_SAE']}\"}\n",
    "]\n",
    "\n",
    "# Create a Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Add prompts to the dataset\n",
    "\n",
    "#dataset = dataset.map(lambda example: {\"prompt\": create_aae_from_sae_prompt(example)})\n",
    "\n",
    "# Function to extract sentiment from model output\n",
    "def extract_sentiment(output):\n",
    "    if \"Positive\" in output:\n",
    "        return \"Positive\"\n",
    "    elif \"Negative\" in output:\n",
    "        return \"Negative\"\n",
    "    elif \"Neutral\" in output:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "\n",
    "def generate_sentiment(sentence):\n",
    "    outputs =  pipeline(\n",
    "       [\n",
    "    {\"role\": \"system\", \"content\": \"Your task is to analyze the provided sentences written in African American English and identify the sentiment expressed by the author. The sentiment must be classified as Positive, Negative, or Neutral. Reply with just the sentiment.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{sentence}\"}\n",
    "],\n",
    "        max_new_tokens=10,\n",
    "        do_sample=False,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    return extract_sentiment(outputs[0][\"generated_text\"])\n",
    "\n",
    "# Function to process a single row\n",
    "def process_row_sentiment(row):\n",
    "    return generate_sentiment(row[\"AAE_from_SAE\"])\n",
    "\n",
    "# Generate sentiments\n",
    "#dataset = dataset.map(\n",
    "#     generate_sentiment,\n",
    "#     batched=True,\n",
    "#     batch_size=32\n",
    "# )\n",
    "\n",
    "print(\"successfully generated models answers\")\n",
    "\n",
    "# Convert back to pandas DataFrame\n",
    "#labeled_df = dataset.to_pandas()\n",
    "\n",
    "# # Save the labeled dataset to a CSV file\n",
    "#output_path = './seperate models/LLama3.1-8b-AAE_from_SAE-Sentiment.csv'\n",
    "#labeled_df[[\"AAE_from_SAE\", \"AAE_from_SAE Sentiment\"]].to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3cbf98ed-427a-4d82-abb2-d56e7624203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the labeled dataset to a CSV file\n",
    "# output_path = './seperate models/LLama3.1-8b-AAE_from_SAE-Sentiment.csv'\n",
    "# labeled_df.rename(columns={\"sentiment\":\"AAE_from_SAE Sentiment\" })[[\"AAE_from_SAE\", \"AAE_from_SAE Sentiment\"]].to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "5a607a65-9997-4302-8b92-46d2c0ea5f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df = pd.read_csv('./seperate models/LLama3.1-8b-AAE_from_SAE-Sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "78b829c2-c8ce-4b7b-823e-1798f58575cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative', 'Positive', 'Neutral', 'Unknown'], dtype=object)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df['AAE_from_SAE Sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "4a3f0eae-79a9-4db6-8b6e-0db14aec836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = labeled_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "2696dfc8-65a5-44d8-9c90-4644c669cdb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AAE_from_SAE', 'AAE_from_SAE Sentiment'], dtype='object')"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "7743afe8-ca33-471f-a8a1-03d989729f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.loc[~test.index.isin([50, 77, 690, 817, 1010, 1775, 1846, 2941])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c01769-8a47-4dba-93b9-a93d0430cdf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "6fce7781-7958-4657-839b-08cbfa076ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/furquanh/miniconda3/envs/augmentation-project/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/local/home/furquanh/miniconda3/envs/augmentation-project/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mask = ~test[\"AAE_from_SAE Sentiment\"].isin([\"Positive\", \"Negative\", \"Neutral\"])\n",
    "test.loc[mask, \"AAE_from_SAE Sentiment\"] = test[mask].apply(process_row_sentiment, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "788ca4b6-1dc0-461c-9a65-73cf2f1cee4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative', 'Positive', 'Neutral'], dtype=object)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['AAE_from_SAE Sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "712c72f2-b37e-4e7e-93ec-27ea8e3f1af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAE_from_SAE</th>\n",
       "      <th>AAE_from_SAE Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [AAE_from_SAE, AAE_from_SAE Sentiment]\n",
       "Index: []"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test[\"AAE_from_SAE Sentiment\"] == 'Unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "5df44f09-5aae-4c08-9bda-5273976625d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('./seperate models/llama-some-removed/LLama3.1-8b-AAE_from_SAE-Sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "278fdedd-8e82-4961-ae52-cd77cc6f4be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files have been processed and saved in the 'some-removed' directory.\n"
     ]
    }
   ],
   "source": [
    "# Define the directory containing the CSV files and the output directory\n",
    "input_directory = './Complete Dataset'  # Replace with your input directory path\n",
    "output_directory = './Complete Dataset/some-removed/'\n",
    "\n",
    "# Indices to be removed\n",
    "indices_to_remove = [50, 77, 690, 817, 1010, 1846, 2941]\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "#os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Loop through every file in the input directory\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(input_directory, filename)\n",
    "        \n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Remove the rows with the specified indices\n",
    "        df_filtered = df.drop(indices_to_remove, errors='ignore')\n",
    "        \n",
    "        # Save the filtered DataFrame to the output directory with the same filename\n",
    "        output_path = os.path.join(output_directory, filename)\n",
    "        df_filtered.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"CSV files have been processed and saved in the 'some-removed' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46698992-4052-40a2-b634-c439744a111f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "augment",
   "language": "python",
   "name": "augmentation-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
