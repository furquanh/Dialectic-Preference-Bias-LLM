{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02a9c506-1f0d-4e95-adae-c9ee4bdcdf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_token = \"huggingface-token-here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "548cfa76-f87f-4ff6-b716-2bf855deb671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a348f50d878443d8f1545f9a7b8db96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21864ae9-30ce-4356-80af-f662891a5073",
   "metadata": {},
   "source": [
    "## Mistral 7B v0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d8855fd-05fb-4aae-b505-40813245f6a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d235a5f023ab47c088db00b0c636ff99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': [{'role': 'system',\n",
       "    'content': 'You are a pirate chatbot who always responds in pirate speak!'},\n",
       "   {'role': 'user', 'content': 'Who are you?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': \" Arr matey! I be the digital parrot, ye scurvy dog! I'll be spinnin' ye yarns and crackin' ye jokes in me hearty pirate tongue. Now, what be ye seekin', landlubber?\\n\\nYe can call me Cap'n Parrot, or just Parrot if ye like. I'll be here to help ye navigate the digital seas and find yer treasure! So, what's\"}]}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "cache_dir = \"../cache\"\n",
    "os.environ['TRANSFORMERS_CACHE'] = cache_dir\n",
    "\n",
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"cuda:0\", \n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    cache_dir=cache_dir, \n",
    "    token=hf_token\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "chatbot = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=100)\n",
    "chatbot(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec9bd26b-71bc-4820-9e91-209bc6408064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': ' Arr matey!'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=4, do_sample=False, num_return_sequences=1, return_full_text=False, pad_token_id=2)\n",
    "chatbot(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4e015bd-3c6a-4af2-9bb9-a959829cf2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Arr matey!\n"
     ]
    }
   ],
   "source": [
    "print(chatbot(messages)[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdd5cdb2-d5e5-489c-a917-91c651f3f7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract sentiment from model output\n",
    "def extract_sentiment(output):\n",
    "    response = output.split(\" \")\n",
    "    if \"Positive\" or \"positive\" in response:\n",
    "        return \"Positive\"\n",
    "    elif \"Negative\" or \"negative\" in response:\n",
    "        return \"Negative\"\n",
    "    elif \"Neutral\" or \"neutral\" in response:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "\n",
    "def generate_sentiment(examples):\n",
    "    outputs = chatbot(\n",
    "       [\n",
    "    {\"role\": \"system\", \"content\": \"Your task is to analyze the provided sentences written in African American English and identify the sentiment expressed by the author. The sentiment must be classified as Positive, Negative, or Neutral. Reply with just the sentiment.\\n\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{examples['text']}\"}\n",
    "]\n",
    "    )\n",
    "    return extract_sentiment(outputs[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c84888e1-954c-437f-8c3f-4a4b42a8e97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function <lambda> at 0x7f769c7bc160> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a6ef6047c74415b9a27e10579cb0df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "\n",
    "datasets.logging.set_verbosity_info()\n",
    "# Load the dataset\n",
    "df = pd.read_csv('./Complete Dataset/GPT-4o-mini-AAE-sentiment.csv')[[\"text\"]]\n",
    "# Create a Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "# Add prompts to the dataset\n",
    "dataset = dataset.map(lambda example: {\"sentiment\": generate_sentiment(example)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "058dfe0c-6dac-4e04-879b-e3834e6a7b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"@islandboi_B yes that's what's up. Nothin like getting dressed up and getting some culture man.\",\n",
       " 'sentiment': 'Positive'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34dc78d2-d9be-4d9e-a069-0a5178ff65f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert back to pandas DataFrame\n",
    "labeled_df = dataset.to_pandas()\n",
    "\n",
    "# Save the labeled dataset to a CSV file\n",
    "output_path = './seperate models/Mistral-AAE-Labels.csv'\n",
    "labeled_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f49b293-804a-4da5-90db-46351d40cd8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative', 'Positive', 'Neutral', 'Unknown'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc1451b3-cc83-4618-8162-119138bef5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ~labeled_df[\"sentiment\"].isin([\"Positive\", \"Negative\", \"Neutral\"])\n",
    "labeled_df.loc[mask, \"sentiment\"] = labeled_df[mask].apply(generate_sentiment, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b8b0d74-1359-49cc-9706-1c422d22f5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         8\n",
       "sentiment    8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df[labeled_df['sentiment'] == 'Unknown'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d32e50-16ac-4935-bcb0-25a469fb2098",
   "metadata": {},
   "source": [
    "_______________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bcbb6ac-2c57-4be0-bff0-c51066e5b4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f34eabee-74f6-4b22-b158-51122bbdf2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./seperate models/Mistral-AAE-Labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a1be687-2bc4-4624-9fc8-affb0c252a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative', 'Positive', 'Neutral', 'Unknown'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4d45d90-57d8-44d8-99cf-54186e7fc270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentiment(output):\n",
    "    response = output.split(\" \")\n",
    "    if \"Positive\" or \"positive\" in response:\n",
    "        return \"Positive\"\n",
    "    elif \"Negative\" or \"negative\" in response:\n",
    "        return \"Negative\"\n",
    "    elif \"Neutral\" or \"neutral\" in response:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "    \n",
    "    \n",
    "def generate_sentiment(sentence):\n",
    "    outputs = chatbot(\n",
    "       [\n",
    "    {\"role\": \"system\", \"content\": \"Your task is to analyze the provided sentences written in African American English and identify the sentiment expressed by the author. The sentiment must be classified as Positive, Negative, or Neutral. Reply with just the sentiment.\\n\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{sentence}\"}\n",
    "]\n",
    "    )\n",
    "    return extract_sentiment(outputs[0][\"generated_text\"])\n",
    "\n",
    "# Function to process a single row\n",
    "def process_row_sentiment(row):\n",
    "    return generate_sentiment(row[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edcb185e-e887-4813-a0d9-5dfbfa235183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process rows with non-standard sentiments\n",
    "mask = ~dataset[\"sentiment\"].isin([\"Positive\", \"Negative\", \"Neutral\"])\n",
    "dataset.loc[mask, \"sentiment\"] = dataset[mask].apply(process_row_sentiment, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d92e53c-6b11-4608-b826-63d564fa1ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative', 'Positive', 'Neutral'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0663a64-1bdc-4ff2-a488-2e5a0a799c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"./seperate models/Mistral-AAE-Labels.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48069f88-e539-4a98-bae5-1c5d0ae2a0f0",
   "metadata": {},
   "source": [
    "## Translation to SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d298546-ca55-4fba-a697-b28f0cdab0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"text\"].to_csv(\"./seperate models/5000_AAE_sentence.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84353fa4-a7f4-4878-9c51-34f3107501b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3755a02a-7966-4b6d-bc21-2b29249a12cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a5a4f3180049b783464f00d0abc99d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function generate_sae at 0x7ff6800f6310> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7cd482b154842d5ade18f7bcfa7a93f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully generated models answers\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['standard_american_english'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/local/home/furquanh/tmp/ipykernel_1005380/1116688241.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Save the labeled dataset to a CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./seperate models/Mistral-SAE.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mlabeled_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"standard_american_english\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"african_american_english\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"SAE dataset saved to {output_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/home/furquanh/miniconda3/envs/augmentation-project/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3897\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3898\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3899\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3901\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/home/furquanh/miniconda3/envs/augmentation-project/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6112\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6114\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6116\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/home/furquanh/miniconda3/envs/augmentation-project/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6177\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6178\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6180\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['standard_american_english'] not in index\""
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "datasets.logging.set_verbosity_info()\n",
    "\n",
    "# Function to create prompts for sentiment analysis\n",
    "def create_prompt(example):\n",
    "    return  [\n",
    "    {\"role\": \"system\", \"content\": \"Following is a tweet extracted from a African American twitter individual's account. Your task is to convert the tweet to Standard American English. Reply with just the sentence.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{example['text']}\"}\n",
    "]\n",
    "\n",
    "# Create a Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Add prompts to the dataset\n",
    "dataset = dataset.map(lambda example: {\"prompt\": create_prompt(example)})\n",
    "\n",
    "# Function to generate sentiments\n",
    "def generate_sae(examples):\n",
    "    outputs = chatbot(\n",
    "      examples[\"prompt\"]\n",
    "    )\n",
    "    return {\"generated_text\": [output[0][\"generated_text\"] for output in outputs]}\n",
    "\n",
    "# Generate sentiments\n",
    "dataset = dataset.map(\n",
    "    generate_sae,\n",
    "    batched=True,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(\"successfully generated models answers\")\n",
    "\n",
    "# Convert back to pandas DataFrame\n",
    "labeled_df = dataset.to_pandas()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6523af8-6e5c-4869-93d3-c26a1225f9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAE dataset saved to ./seperate models/Mistral-SAE.csv\n",
      "Number of processed sentences: 5000\n"
     ]
    }
   ],
   "source": [
    "# Save the labeled dataset to a CSV file\n",
    "output_path = './seperate models/Mistral-SAE.csv'\n",
    "labeled_df[[\"text\", \"generated_text\"]].rename(columns={\"text\": \"african_american_english\", \"generated_text\" : \"standard_american_english\"}).to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"SAE dataset saved to {output_path}\")\n",
    "print(f\"Number of processed sentences: {len(labeled_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc54cc6-643a-4639-9c16-5df445708e65",
   "metadata": {},
   "source": [
    "# Getting labels for SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62bea4c8-9d18-4b6a-a5e8-c871de4bc28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./seperate models/Mistral-SAE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a27bfbd0-7ce2-4d4f-817e-3616c5680323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a1f7c04a0e2441f9f8f65d03fe0b443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function generate_sae_labels at 0x7f9e1ec00280> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f07498aa3db442ea898325bd6ab4d822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully generated models answers\n",
      "SAE dataset saved to ./seperate models/Mistral-SAE-sentiment.csv\n",
      "Number of processed sentences: 5000\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "datasets.logging.set_verbosity_info()\n",
    "\n",
    "\n",
    "# Function to create prompts for sentiment analysis\n",
    "def create_prompt(example):\n",
    "    return  [\n",
    "    {\"role\": \"system\", \"content\": \"Your task is to analyze the provided sentences written in Standard American English and identify the sentiment expressed by the author. Reply back in one word with just the sentiment, Positive, Negative, or Neutral only\\n\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{example['standard_american_english']}\"}\n",
    "]\n",
    "\n",
    "# Create a Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Add prompts to the dataset\n",
    "dataset = dataset.map(lambda example: {\"prompt\": create_prompt(example)})\n",
    "\n",
    "def extract_sentiment(output):\n",
    "    response = output.split(\" \")\n",
    "    if \"Positive\" in response:\n",
    "        return \"Positive\"\n",
    "    elif \"Negative\"  in response:\n",
    "        return \"Negative\"\n",
    "    elif \"Neutral\" in response:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# Function to generate sentiments\n",
    "def generate_sae_labels(examples):\n",
    "    outputs = chatbot(\n",
    "      examples[\"prompt\"]\n",
    "    )\n",
    "    return {\"sae_labels\": [extract_sentiment(output[0][\"generated_text\"]) for output in outputs],\n",
    "           \"model_generation\" : [output[0][\"generated_text\"] for output in outputs]}\n",
    "\n",
    "# Generate sentiments\n",
    "dataset = dataset.map(\n",
    "    generate_sae_labels,\n",
    "    batched=True,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(\"successfully generated models answers\")\n",
    "\n",
    "# Convert back to pandas DataFrame\n",
    "labeled_df = dataset.to_pandas()\n",
    "\n",
    "output_path = './seperate models/Mistral-SAE-sentiment.csv'\n",
    "labeled_df[[\"standard_american_english\", \"sae_labels\", \"model_generation\"]].to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"SAE dataset saved to {output_path}\")\n",
    "print(f\"Number of processed sentences: {len(labeled_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7647539-b4a5-43ff-9217-b402f293c3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentiment(sentence):\n",
    "    outputs = chatbot(\n",
    "      text_inputs=  [\n",
    "    {\"role\": \"system\", \"content\": \"Your task is to analyze the provided sentences written in Standard American English and identify the sentiment expressed by the author. The sentiment must be classified as Positive, Negative, or Neutral. Reply with just the sentiment.\\n\\n\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{sentence}\"}\n",
    "],\n",
    "        max_new_tokens=15,\n",
    "        do_sample=False,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    return extract_sentiment(outputs[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "66bd1ac0-3920-4b14-b547-bc1d5a3aeaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process a single row\n",
    "def process_row_sentiment(row):\n",
    "    return generate_sentiment(row['standard_american_english'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4b1e3b74-e76c-406c-9e73-0d3404b3a7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = labeled_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3c12bb0-dc8a-46ee-98a4-6e267978b5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process rows with non-standard sentiments\n",
    "mask = ~test[\"sae_labels\"].isin([\"Positive\", \"Negative\", \"Neutral\"])\n",
    "test.loc[mask, \"sae_labels\"] = test[mask].apply(process_row_sentiment, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e61bead4-0ad6-453a-a3a8-2ae98541366f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sae_labels\n",
       "Negative    2218\n",
       "Positive    1881\n",
       "Neutral      901\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['sae_labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c37355a-0edb-402b-bfd7-643a024a07fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>african_american_english</th>\n",
       "      <th>standard_american_english</th>\n",
       "      <th>prompt</th>\n",
       "      <th>sae_labels</th>\n",
       "      <th>model_generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>Ima stop listening to music and go on nexflix....</td>\n",
       "      <td>I will stop listening to music and switch to ...</td>\n",
       "      <td>[{'content': 'Your task is to analyze the prov...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Neutral,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               african_american_english  \\\n",
       "1905  Ima stop listening to music and go on nexflix....   \n",
       "\n",
       "                              standard_american_english  \\\n",
       "1905   I will stop listening to music and switch to ...   \n",
       "\n",
       "                                                 prompt sae_labels  \\\n",
       "1905  [{'content': 'Your task is to analyze the prov...    Unknown   \n",
       "\n",
       "     model_generation  \n",
       "1905         Neutral,  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test['sae_labels'] == 'Unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72f4fea9-4ca9-45d8-8896-7e395b3383c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test['sae_labels'] == 'Unknown', 'sae_labels'] = 'Neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b5f28df-ff5d-4f02-8708-f471493d53d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>african_american_english</th>\n",
       "      <th>standard_american_english</th>\n",
       "      <th>prompt</th>\n",
       "      <th>sae_labels</th>\n",
       "      <th>model_generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [african_american_english, standard_american_english, prompt, sae_labels, model_generation]\n",
       "Index: []"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test['sae_labels'] == 'Unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af52e065-5fe1-4716-850b-a114710633e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = './seperate models/Mistral-SAE-sentiment.csv'\n",
    "test[[\"standard_american_english\", \"sae_labels\"]].to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06f1761-95da-4ded-a623-2cff2302caf0",
   "metadata": {},
   "source": [
    "## Converting back to AAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ef559e8-3974-4d19-bb5e-9e45866f6777",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./seperate models/Mistral-SAE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75bfb524-8270-4f9a-9203-5b1e69eafd55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9789180ab614f9795ed1a828cd497f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function generate_aae_from_sae at 0x7f8f212e3ee0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "797b800946634dc1add9ddc2e81beb41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully generated models answers\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "datasets.logging.set_verbosity_info()\n",
    "\n",
    "# Function to create prompts for sentiment analysis\n",
    "def create_aae_from_sae_prompt(example):\n",
    "    return  [\n",
    "    {\"role\": \"system\", \"content\": \"You will be given a tweet in Standard American English. Your task is to convert the given tweet to African American English. Reply with just the translated sentence.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{example['standard_american_english']}\"}\n",
    "]\n",
    "\n",
    "# Create a Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Add prompts to the dataset\n",
    "dataset = dataset.map(lambda example: {\"prompt\": create_aae_from_sae_prompt(example)})\n",
    "\n",
    "# Function to generate sentiments\n",
    "def generate_aae_from_sae(examples):\n",
    "    outputs = chatbot(\n",
    "      examples[\"prompt\"],\n",
    "    max_new_tokens=150,\n",
    "        do_sample=False,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    return {\"AAE_from_SAE\": [output[0][\"generated_text\"] for output in outputs]}\n",
    "\n",
    "# Generate sentiments\n",
    "dataset = dataset.map(\n",
    "    generate_aae_from_sae,\n",
    "    batched=True,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(\"successfully generated models answers\")\n",
    "\n",
    "# Convert back to pandas DataFrame\n",
    "labeled_df = dataset.to_pandas()\n",
    "\n",
    "output_path = './seperate models/Mistral-AAE_from_SAE.csv'\n",
    "labeled_df[[\"standard_american_english\", \"AAE_from_SAE\"]].to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88a8ca0-c00b-4065-afb3-dec65baf9848",
   "metadata": {},
   "source": [
    "## AAE_from_SAE sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4040dacb-4bc9-458f-9338-3a5f912123b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d9796b617c49a5aed975892a057d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function generate_sentiment_aae_from_sae at 0x7f8ae16309d0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f9b896b148a49c78470212b77886413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully generated models answers\n",
      "AAE_from_SAE-sentiment dataset saved to ./seperate models/Mistral-AAE_from_SAE-sentiment.csv\n",
      "Number of processed sentences: 5000\n"
     ]
    }
   ],
   "source": [
    "# Function to create prompts for sentiment analysis\n",
    "def create_prompt_aae_from_sae(example):\n",
    "    return  [\n",
    "    {\"role\": \"system\", \"content\": \"Your task is to analyze the provided sentences written in African American English and identify the sentiment expressed by the author. The sentiment must be classified as Positive, Negative, or Neutral. Reply with just the sentiment.\\n\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{example['AAE_from_SAE']}\"}\n",
    "]\n",
    "\n",
    "# Create a Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(labeled_df[[\"AAE_from_SAE\"]])\n",
    "\n",
    "# Add prompts to the dataset\n",
    "dataset = dataset.map(lambda example: {\"prompt\": create_prompt_aae_from_sae(example)})\n",
    "\n",
    "# Function to extract sentiment from model output\n",
    "def extract_sentiment(response):\n",
    "    if \"Positive\"  in response:\n",
    "        return \"Positive\"\n",
    "    elif \"Negative\"  in response:\n",
    "        return \"Negative\"\n",
    "    elif \"Neutral\" in response:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "\n",
    "def generate_sentiment_aae_from_sae(examples):\n",
    "    outputs = chatbot(\n",
    "       examples['prompt']\n",
    "    )\n",
    "    return {\"AAE_from_SAE-sentiment\" : [extract_sentiment(output[0][\"generated_text\"]) for output in outputs]}\n",
    "\n",
    "# Generate sentiments\n",
    "dataset = dataset.map(\n",
    "    generate_sentiment_aae_from_sae,\n",
    "    batched=True,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(\"successfully generated models answers\")\n",
    "\n",
    "# Convert back to pandas DataFrame\n",
    "labeled_df = dataset.to_pandas()\n",
    "\n",
    "output_path = './seperate models/Mistral-AAE_from_SAE-sentiment.csv'\n",
    "labeled_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"AAE_from_SAE-sentiment dataset saved to {output_path}\")\n",
    "print(f\"Number of processed sentences: {len(labeled_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ea62379-91f3-463f-a699-b39ef567c348",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df[[\"AAE_from_SAE\", \"AAE_from_SAE-sentiment\"]].to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb990f2e-2153-43a7-bae1-6df30d6366be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "already_labeled = pd.read_csv(\"./seperate models/Mistral-AAE_from_SAE-sentiment.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b9a1c9a-6f1c-4427-a73d-daedba04394e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative', 'Positive', 'Neutral'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "already_labeled[\"AAE_from_SAE-sentiment\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f3e374-a9dd-442d-8f9c-0b77cfa2fb7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "augment",
   "language": "python",
   "name": "augmentation-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
