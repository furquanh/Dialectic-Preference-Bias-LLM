{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf4c9ec2-7f82-4894-b55c-3e0aa02bca35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "from groq import Groq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "963c1530-1e34-4c8f-89a9-af4636605bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = \"./cache/\"\n",
    "os.environ['TRANSFORMERS_CACHE'] = cache_dir\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = \"false\"\n",
    "os.environ['OPENAI_API_KEY'] = 'openai-api-key-here'\n",
    "os.environ['ANTHROPIC_API_KEY'] = 'anthropic-api-key-here'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5ab4305-1562-4c19-ad66-d5e38cf6f559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from tqdm import tqdm\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Define the schema for sentiment analysis\n",
    "# Define the schema for sentiment analysis\n",
    "class StandardEnglish(BaseModel):\n",
    "    standard_english: str = Field(description=\"The tweet converted into Standard American English.\")\n",
    "\n",
    "class Data(BaseModel):\n",
    "    \"\"\"Convert the list of tweets provided to standard american english.\"\"\"\n",
    "    standard_english_tweets: List[StandardEnglish] = Field(description=\"The list of converted tweets by order of the sentences given.\")\n",
    "\n",
    "# Define the prompt template\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You will be given a list of tweets extracted from twitter accounts belonging to African American individuals. Your task is to convert the given tweet to Standard American English.\"\"\"\n",
    "        ),\n",
    "        (\"user\", \"{sentences}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the language model\n",
    "# model = ChatAnthropic(model=\"claude-3-haiku-20240307\", timeout=None,\n",
    "#     max_retries=2, temperature=0)\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", timeout=None,\n",
    "    max_retries=2, temperature=0)\n",
    "\n",
    "# Create the runnable chain\n",
    "runnable = chat_template | model.with_structured_output(schema=Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c49763d-62d8-44de-a6de-79beda42a7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#runnable.invoke({\"sentences\":\"I wanna scream and shout and let it all outtt and scream and shout and let it out we sayin' ohhhweeee oh we oh we ohhhhh!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be865bed-0310-47df-8a7f-c3542572387e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aae_dataset = pd.read_csv('initial_2000_sentences.csv')[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d7f5fc5-395a-4f85-b90d-1374bf659f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sae_sentence = []\n",
    "processed_indices = []\n",
    "failed_indices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89db1c39-fbff-43c2-9915-ef0468e2e88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled dataset saved to ./labeled/anthropic_Haiku-SAE.csv\n",
      "Failed indices saved to ./labeled/failed_indices_anthropic_Haiku-SAE.csv\n",
      "Number of successfully processed sentences: 1620\n",
      "Number of failed sentences: 380\n"
     ]
    }
   ],
   "source": [
    "# Process the dataset in batches of 10\n",
    "# for i in tqdm(range(0, len(aae_dataset), 5)):\n",
    "#     batch = aae_dataset[i:i+5].to_list()\n",
    "#     batch_indices = list(range(i, min(i+5, len(aae_dataset))))\n",
    "    \n",
    "#     try:\n",
    "#         result = runnable.invoke({\"sentences\": \"\\n\".join(batch)})\n",
    "        \n",
    "#         # Check if the number of returned sentiments matches the batch size\n",
    "#         if len(result.standard_english_tweets) == len(batch):\n",
    "#             all_sae_sentence.extend([response.standard_english for response in result.standard_english_tweets])\n",
    "#             processed_indices.extend(batch_indices)\n",
    "#         else:\n",
    "#             # If the number of sentiments doesn't match, mark all as failed\n",
    "#             failed_indices.extend(batch_indices)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing batch {i}-{i+4}: {str(e)}\")\n",
    "#         failed_indices.extend(batch_indices)\n",
    "\n",
    "# Create a new dataframe with successfully processed sentences and sentiments\n",
    "labeled_df = pd.DataFrame({\n",
    "    'index': processed_indices,\n",
    "    'text': aae_dataset.iloc[processed_indices],\n",
    "    'standard_american_english': all_sae_sentence\n",
    "})\n",
    "\n",
    "# Sort the dataframe by the original index\n",
    "labeled_df = labeled_df.sort_values('index').reset_index(drop=True)\n",
    "\n",
    "# Save the labeled dataset to a CSV file\n",
    "output_path = './labeled/anthropic_Haiku-SAE.csv'\n",
    "labeled_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Labeled dataset saved to {output_path}\")\n",
    "\n",
    "# Save the failed indices to a separate file\n",
    "failed_indices_path = './labeled/failed_indices_anthropic_Haiku-SAE.csv'\n",
    "pd.DataFrame({'failed_index': failed_indices}).to_csv(failed_indices_path, index=False)\n",
    "\n",
    "print(f\"Failed indices saved to {failed_indices_path}\")\n",
    "print(f\"Number of successfully processed sentences: {len(processed_indices)}\")\n",
    "print(f\"Number of failed sentences: {len(failed_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff879606-e758-4584-b814-d32308dc0d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1620"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_sae_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c48ada3-3626-499a-925c-3805446e957e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 127/127 [03:19<00:00,  1.57s/it]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'original_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/local/home/furquanh/tmp/ipykernel_1356641/4071737401.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m new_labeled_df = pd.DataFrame({\n\u001b[1;32m     31\u001b[0m     \u001b[0;34m'index'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_processed_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moriginal_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_processed_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;34m'standard_american_english'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_sentiments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m })\n",
      "\u001b[0;31mNameError\u001b[0m: name 'original_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the previously processed data\n",
    "labeled_df = pd.read_csv('./labeled/anthropic_Haiku-SAE.csv')\n",
    "failed_indices = pd.read_csv('./labeled/failed_indices_anthropic_Haiku-SAE.csv')['failed_index'].tolist()\n",
    "\n",
    "# Initialize lists to store the new sentiments and their corresponding indices\n",
    "new_sentiments = []\n",
    "new_processed_indices = []\n",
    "still_failed_indices = []\n",
    "\n",
    "# Process the failed sentences\n",
    "for i in tqdm(range(0, len(failed_indices), 3)):\n",
    "    batch_indices = failed_indices[i:i+3]\n",
    "    batch = aae_dataset.iloc[batch_indices].tolist()\n",
    "    \n",
    "    try:\n",
    "        result = runnable.invoke({\"sentences\": \"\\n\".join(batch)})\n",
    "        \n",
    "        # Check if the number of returned sentiments matches the batch size\n",
    "        if len(result.standard_english_tweets) == len(batch):\n",
    "            new_sentiments.extend([response.standard_english for response in result.standard_english_tweets])\n",
    "            new_processed_indices.extend(batch_indices)\n",
    "        else:\n",
    "            # If the number of sentiments doesn't match, mark all as still failed\n",
    "            still_failed_indices.extend(batch_indices)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {i}-{i+2}: {str(e)}\")\n",
    "        still_failed_indices.extend(batch_indices)\n",
    "\n",
    "# Create a new dataframe with newly processed sentences and sentiments\n",
    "new_labeled_df = pd.DataFrame({\n",
    "    'index': new_processed_indices,\n",
    "    'text': original_dataset.iloc[new_processed_indices],\n",
    "    'standard_american_english': new_sentiments\n",
    "})\n",
    "\n",
    "# Combine the previously processed data with the newly processed data\n",
    "combined_df = pd.concat([labeled_df, new_labeled_df], ignore_index=True)\n",
    "\n",
    "# Sort the dataframe by the original index and reset the index\n",
    "combined_df = combined_df.sort_values('index').reset_index(drop=True)\n",
    "\n",
    "# If there are still failed indices, add them to the combined dataframe with NaN sentiment\n",
    "if still_failed_indices:\n",
    "    failed_df = pd.DataFrame({\n",
    "        'index': still_failed_indices,\n",
    "        'text': original_dataset.iloc[still_failed_indices],\n",
    "        'sentiment': pd.NA\n",
    "    })\n",
    "    combined_df = pd.concat([combined_df, failed_df], ignore_index=True)\n",
    "    combined_df = combined_df.sort_values('index').reset_index(drop=True)\n",
    "\n",
    "# Save the complete labeled dataset to a CSV file\n",
    "output_path = './labeled/complete-2000-Haiku-SAE-Convert.csv'\n",
    "combined_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Complete labeled dataset saved to {output_path}\")\n",
    "print(f\"Total processed sentences: {len(combined_df)}\")\n",
    "print(f\"Successfully labeled sentences: {combined_df['sentiment'].notna().sum()}\")\n",
    "print(f\"Failed sentences: {combined_df['sentiment'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9284010f-cd30-4644-b0f4-f330c99c0a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete labeled dataset saved to ./labeled/complete-2000-Haiku-SAE-Convert.csv\n",
      "Total processed sentences: 2000\n",
      "Successfully labeled sentences: 0\n",
      "Failed sentences: 2000\n"
     ]
    }
   ],
   "source": [
    "# Create a new dataframe with newly processed sentences and sentiments\n",
    "new_labeled_df = pd.DataFrame({\n",
    "    'index': new_processed_indices,\n",
    "    'text': aae_dataset.iloc[new_processed_indices],\n",
    "    'standard_american_english': new_sentiments\n",
    "})\n",
    "\n",
    "# Combine the previously processed data with the newly processed data\n",
    "combined_df = pd.concat([labeled_df, new_labeled_df], ignore_index=True)\n",
    "\n",
    "# Sort the dataframe by the original index and reset the index\n",
    "combined_df = combined_df.sort_values('index').reset_index(drop=True)\n",
    "\n",
    "# If there are still failed indices, add them to the combined dataframe with NaN sentiment\n",
    "if still_failed_indices:\n",
    "    failed_df = pd.DataFrame({\n",
    "        'index': still_failed_indices,\n",
    "        'text': aae_dataset.iloc[still_failed_indices],\n",
    "        'sentiment': pd.NA\n",
    "    })\n",
    "    combined_df = pd.concat([combined_df, failed_df], ignore_index=True)\n",
    "    combined_df = combined_df.sort_values('index').reset_index(drop=True)\n",
    "\n",
    "# Save the complete labeled dataset to a CSV file\n",
    "output_path = './labeled/complete-2000-Haiku-SAE-Convert.csv'\n",
    "combined_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Complete labeled dataset saved to {output_path}\")\n",
    "print(f\"Total processed sentences: {len(combined_df)}\")\n",
    "print(f\"Successfully labeled sentences: {combined_df['sentiment'].notna().sum()}\")\n",
    "print(f\"Failed sentences: {combined_df['sentiment'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5387496-5c06-472d-a1ae-8724ccb25d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_haiku_sae = pd.read_csv(output_path)\n",
    "final_haiku_sae['standard_american_english'] = final_haiku_sae.apply(\n",
    "    lambda row: runnable_single.invoke({\"sentences\": row['text']}).standard_english_tweets[0].standard_english if pd.isna(row['standard_american_english']) or row['standard_american_english'] == '' else row['standard_american_english'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Rename the 'text' column to 'aae'\n",
    "final_haiku_sae.rename(columns={'text': 'aae'}, inplace=True)\n",
    "\n",
    "# Keep only the 'aae' and 'standard_american_english' columns\n",
    "final_haiku_sae = final_haiku_sae[['aae', 'standard_american_english']]\n",
    "\n",
    "# Save the transformed dataset to a new CSV file\n",
    "output_path = './labeled/complete-2000-Haiku-SAE-Convert-FINAL.csv'\n",
    "final_haiku_sae.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ceaf9d-dbe4-45c5-8a25-127aab6eb7ba",
   "metadata": {},
   "source": [
    "## Getting labels for SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7a0cc785-f8f3-464e-9f36-4ed8f2d31a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema for sentiment analysis\n",
    "# Define the schema for sentiment analysis\n",
    "class SentimentAnalysisResponse(BaseModel):\n",
    "    sentiment: str = Field(description=\"The sentiment of the sentence (Positive, Negative, or Neutral)\")\n",
    "\n",
    "class Data(BaseModel):\n",
    "    \"\"\"Extracted data about sentences.\"\"\"\n",
    "    sentiments: List[SentimentAnalysisResponse]\n",
    "\n",
    "# Define the prompt template\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"Your task is to analyze the provided sentences written in Standard American English and identify the sentiment expressed by the author. The sentiment should be classified as Positive, Negative, or Neutral for each sentence.\"\"\"\n",
    "        ),\n",
    "        (\"user\", \"{sentences}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the language model\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "\n",
    "# Create the runnable chain\n",
    "sae_labels_runnable = chat_template | model.with_structured_output(schema=Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d6a0ba37-3154-4da3-bc91-49163484015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sae_sentiment = []\n",
    "processed_indices = []\n",
    "failed_indices = []\n",
    "sae_dataset = pd.read_csv('./labeled/gpt-3.5-sae.csv')['sae_sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3502e04e-3696-453e-9706-03a90ffd842b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Bitch can't get anything from me but bubble gum and hard dick from me. I told the bitch I'm trying to make a profit. I'm shooting dice with her rent money!\""
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c91f662d-29bb-4dc5-9841-fa947a14db65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█▉                                  | 11/200 [00:11<03:03,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing batch 110-119: sequence item 0: expected str instance, float found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████▋         | 147/200 [02:38<01:01,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing batch 1470-1479: sequence item 0: expected str instance, float found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|██████████████████████████████████▏| 195/200 [03:31<00:05,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing batch 1950-1959: sequence item 0: expected str instance, float found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 200/200 [03:35<00:00,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled dataset saved to ./labeled/gpt-3.5-sae-labels.csv\n",
      "Failed indices saved to ./labeled/failed_indices_gpt-3.5-sae-labels.csv\n",
      "Number of successfully processed sentences: 1530\n",
      "Number of failed sentences: 470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Process the dataset in batches of 10\n",
    "for i in tqdm(range(0, len(sae_dataset), 10)):\n",
    "    batch = sae_dataset[i:i+10].to_list()\n",
    "    batch_indices = list(range(i, min(i+10, len(sae_dataset))))\n",
    "    \n",
    "    try:\n",
    "        result = sae_labels_runnable.invoke({\"sentences\": \"\\n\".join(batch)})\n",
    "        \n",
    "        # Check if the number of returned sentiments matches the batch size\n",
    "        if len(result.sentiments) == len(batch):\n",
    "            all_sae_sentiment.extend([response.sentiment for response in result.sentiments])\n",
    "            processed_indices.extend(batch_indices)\n",
    "        else:\n",
    "            # If the number of sentiments doesn't match, mark all as failed\n",
    "            failed_indices.extend(batch_indices)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {i}-{i+9}: {str(e)}\")\n",
    "        failed_indices.extend(batch_indices)\n",
    "\n",
    "# Create a new dataframe with successfully processed sentences and sentiments\n",
    "labeled_df_sae_labels = pd.DataFrame({\n",
    "    'index': processed_indices,\n",
    "    'standard_american_english': sae_dataset.iloc[processed_indices],\n",
    "    'sae_labels': all_sae_sentiment\n",
    "})\n",
    "\n",
    "# Sort the dataframe by the original index\n",
    "labeled_df_sae_labels = labeled_df_sae_labels.sort_values('index').reset_index(drop=True)\n",
    "\n",
    "# Save the labeled dataset to a CSV file\n",
    "output_path = './labeled/gpt-3.5-sae-labels.csv'\n",
    "labeled_df_sae_labels.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Labeled dataset saved to {output_path}\")\n",
    "\n",
    "# Save the failed indices to a separate file\n",
    "failed_indices_path = './labeled/failed_indices_gpt-3.5-sae-labels.csv'\n",
    "pd.DataFrame({'failed_index': failed_indices}).to_csv(failed_indices_path, index=False)\n",
    "\n",
    "print(f\"Failed indices saved to {failed_indices_path}\")\n",
    "print(f\"Number of successfully processed sentences: {len(processed_indices)}\")\n",
    "print(f\"Number of failed sentences: {len(failed_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "efb3e540-6cb4-4416-b9f8-9edce021a93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete labeled dataset saved to ./labeled/gpt-3.5-sae-labels-updated.csv\n",
      "Total processed sentences: 2000\n",
      "Successfully labeled sentences: 2000\n",
      "Failed sentences: 0\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "combined_df_sae_labels = pd.read_csv('./labeled/gpt-3.5-sae-labels.csv')\n",
    "\n",
    "# Find the indices of the failed sentences\n",
    "failed_indices = combined_df_sae_labels[combined_df_sae_labels['sae_labels'].isna()].index\n",
    "\n",
    "# Iterate over the failed sentences and get their labels\n",
    "for index in failed_indices:\n",
    "    failed_sentence = combined_df_sae_labels.loc[index, 'standard_american_english']\n",
    "    # Invoke the SAE labels runnable to get the label\n",
    "    label = sae_labels_runnable.invoke({\"sentences\": failed_sentence}).sentiments[0].sentiment\n",
    "    # Update the DataFrame with the new label\n",
    "    combined_df_sae_labels.loc[index, 'sae_labels'] = label\n",
    "\n",
    "# Save the updated dataset\n",
    "output_path = './labeled/gpt-3.5-sae-labels-updated.csv'\n",
    "combined_df_sae_labels.to_csv(output_path, index=False)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Complete labeled dataset saved to {output_path}\")\n",
    "print(f\"Total processed sentences: {len(combined_df_sae_labels)}\")\n",
    "print(f\"Successfully labeled sentences: {combined_df_sae_labels['sae_labels'].notna().sum()}\")\n",
    "print(f\"Failed sentences: {combined_df_sae_labels['sae_labels'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6eb7c544-10ab-413b-9761-4c8aadc99a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated dataset\n",
    "output_path = './labeled/gpt-3.5-sae-labels-updated.csv'\n",
    "combined_df_sae_labels[[\"standard_american_english\", \"sae_labels\"]].to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9bac8586-dfce-4c52-9acd-42719bf219fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▎                                 | 10/157 [00:06<01:41,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing batch 30-32: sequence item 0: expected str instance, float found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|██████████████████████████▊        | 120/157 [01:14<00:21,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing batch 360-362: sequence item 0: expected str instance, float found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|████████████████████████████████▌  | 146/157 [01:31<00:07,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing batch 438-440: sequence item 2: expected str instance, float found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 157/157 [01:37<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete labeled dataset saved to ./labeled/gpt-3.5-sae-labels.csv\n",
      "Total processed sentences: 2000\n",
      "Successfully labeled sentences: 1934\n",
      "Failed sentences: 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the previously processed data\n",
    "labeled_df = pd.read_csv('./labeled/gpt-3.5-sae-labels.csv')\n",
    "failed_indices = pd.read_csv('./labeled/failed_indices_gpt-3.5-sae-labels.csv')['failed_index'].tolist()\n",
    "\n",
    "\n",
    "# Initialize lists to store the new sentiments and their corresponding indices\n",
    "new_sentiments = []\n",
    "new_processed_indices = []\n",
    "still_failed_indices = []\n",
    "\n",
    "# Process the failed sentences\n",
    "for i in tqdm(range(0, len(failed_indices), 3)):\n",
    "    batch_indices = failed_indices[i:i+3]\n",
    "    batch = sae_dataset.iloc[batch_indices].tolist()\n",
    "    \n",
    "    try:\n",
    "        result = sae_labels_runnable.invoke({\"sentences\": \"\\n\".join(batch)})\n",
    "        \n",
    "        # Check if the number of returned sentiments matches the batch size\n",
    "        if len(result.sentiments) == len(batch):\n",
    "            new_sentiments.extend([response.sentiment for response in result.sentiments])\n",
    "            new_processed_indices.extend(batch_indices)\n",
    "        else:\n",
    "            # If the number of sentiments doesn't match, mark all as still failed\n",
    "            still_failed_indices.extend(batch_indices)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {i}-{i+2}: {str(e)}\")\n",
    "        still_failed_indices.extend(batch_indices)\n",
    "\n",
    "# Create a new dataframe with newly processed sentences and sentiments\n",
    "new_labeled_df_sae_labels = pd.DataFrame({\n",
    "    'index': new_processed_indices,\n",
    "    'standard_american_english': sae_dataset.iloc[new_processed_indices],\n",
    "    'sae_labels': new_sentiments\n",
    "})\n",
    "\n",
    "# Combine the previously processed data with the newly processed data\n",
    "combined_df_sae_labels = pd.concat([labeled_df_sae_labels, new_labeled_df_sae_labels], ignore_index=True)\n",
    "\n",
    "# Sort the dataframe by the original index and reset the index\n",
    "combined_df_sae_labels = combined_df_sae_labels.sort_values('index').reset_index(drop=True)\n",
    "\n",
    "# If there are still failed indices, add them to the combined dataframe with NaN sentiment\n",
    "if still_failed_indices:\n",
    "    failed_df = pd.DataFrame({\n",
    "        'index': still_failed_indices,\n",
    "        'standard_american_english': sae_dataset.iloc[still_failed_indices],\n",
    "        'sae_labels': pd.NA\n",
    "    })\n",
    "    combined_df_sae_labels = pd.concat([combined_df_sae_labels, failed_df], ignore_index=True)\n",
    "    combined_df_sae_labels = combined_df_sae_labels.sort_values('index').reset_index(drop=True)\n",
    "\n",
    "# Save the complete labeled dataset to a CSV file\n",
    "output_path = './labeled/gpt-3.5-sae-labels.csv'\n",
    "combined_df_sae_labels.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Complete labeled dataset saved to {output_path}\")\n",
    "print(f\"Total processed sentences: {len(combined_df_sae_labels)}\")\n",
    "print(f\"Successfully labeled sentences: {combined_df_sae_labels['sae_labels'].notna().sum()}\")\n",
    "print(f\"Failed sentences: {combined_df_sae_labels['sae_labels'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c359b1ed-9887-4a0a-8894-27e11183bba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df_sae_labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a9076e2b-0578-436f-bed6-deb4ab7e6229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully labeled sentences: 2000\n",
      "Failed sentences: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Successfully labeled sentences: {combined_df_sae_labels['sae_labels'].notna().sum()}\")\n",
    "print(f\"Failed sentences: {combined_df_sae_labels['sae_labels'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c6fbaede-5b85-4d0c-9c1c-abfb6d2ac0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "aab = combined_df_sae_labels[combined_df_sae_labels['sae_labels'].isna()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "08db5282-e151-4a0c-9030-55487be829aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = './labeled/complete-2000-Haiku-SAE-FINAL-Labels.csv'\n",
    "combined_df_sae_labels[[\"standard_american_english\", \"sae_labels\"]].to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "258f4a4c-c689-4be4-9351-0748866bbde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df_sae_labels.loc[1850, 'sae_labels'] = sae_labels_runnable.invoke({\"sentences\": combined_df_sae_labels.loc[1850, 'standard_american_english']}).sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "38119b01-1175-47c4-a455-667ecab766f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "aae_sae = pd.read_csv('./labeled/complete-2000-Haiku-SAE-Convert-FINAL.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1aeb0ccc-eb2f-497f-b389-cac7bf8cf39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aae                          @LoveGamesOxygen who made amy dress for the fi...\n",
       "standard_american_english    Who made Amy's dress for the finale, the red o...\n",
       "Name: 968, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aae_sae.iloc[968]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9aa75b9b-fb6f-41fa-8486-11250715af99",
   "metadata": {},
   "outputs": [],
   "source": [
    "aae_sae.loc[968, 'standard_american_english'] = runnable.invoke({\"sentences\": aae_sae.loc[968, 'aae']}).standard_english_tweets[0].standard_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b05f2ede-3e36-4d78-9d07-34d36568b7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "aae_sae.to_csv('./labeled/complete-2000-Haiku-SAE-Convert-FINAL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5eeca1-ad72-4b94-a992-0776a88f747f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "augment",
   "language": "python",
   "name": "augmentation-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
