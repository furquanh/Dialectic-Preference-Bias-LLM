{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d103a174-ac76-4f10-a338-706601a9b112",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from collections import Counter\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "from groq import Groq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54aa2db1-6f12-4089-921e-4488b53f5a27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cache_dir = \"./cache/\"\n",
    "os.environ['TRANSFORMERS_CACHE'] = cache_dir\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = \"false\"\n",
    "os.environ['OPENAI_API_KEY'] = 'openai-api-key-here'\n",
    "os.environ['ANTHROPIC_API_KEY'] = 'anthropic-api-key-here'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca3a65ae-3872-4a3c-b42c-c040b066def8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bitch cant get shit from me but bubble gum nd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@islandboi_B yes that's what's up. Nothin like...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mixed huh !? Those black ass knees and elbows ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The bul Mike James from @mavs ain't shit n he ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It took for a whole stranger to tell me he PRO...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Bitch cant get shit from me but bubble gum nd ...\n",
       "1  @islandboi_B yes that's what's up. Nothin like...\n",
       "2  Mixed huh !? Those black ass knees and elbows ...\n",
       "3  The bul Mike James from @mavs ain't shit n he ...\n",
       "4  It took for a whole stranger to tell me he PRO..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to filter out problematic sentences\n",
    "def is_valid_sentence(sentence):\n",
    "    # Define regex patterns to match problematic characters or structures\n",
    "    pattern1 = re.compile(r'[^\\x00-\\x7F]+|[\\x00-\\x1F\\x7F]')  # Non-ASCII and control characters\n",
    "    pattern2 = re.compile(r'[\\\\]')  # Backslashes\n",
    "    \n",
    "    # Return True only if the sentence matches neither pattern\n",
    "    return not (pattern1.search(sentence) or pattern2.search(sentence))\n",
    "\n",
    "# Read the dataset\n",
    "dataset = pd.read_csv('cleaned_dataset.csv')\n",
    "\n",
    "# Filter out problematic sentences\n",
    "dataset['text'] = dataset['text'].apply(lambda x: x if is_valid_sentence(x) else None)\n",
    "dataset = dataset.dropna().reset_index(drop=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9f3a706-4f0a-4d34-bd92-c9b719966bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[:2000].to_csv('initial_2000_sentences.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0598cf-a9c9-4099-b3a0-45d7b423c79f",
   "metadata": {},
   "source": [
    "## The below is API script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5b9b33da-3815-446b-a1c0-928537bf9892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results are: sentiments=[SentimentAnalysisResponse(sentiment='Positive'), SentimentAnalysisResponse(sentiment='Neutral'), SentimentAnalysisResponse(sentiment='Negative')]\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Optional\n",
    "from tqdm import tqdm\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Define the schema for sentiment analysis\n",
    "# Define the schema for sentiment analysis\n",
    "class SentimentAnalysisResponse(BaseModel):\n",
    "    sentiment: str = Field(description=\"The sentiment of the sentence (Positive, Negative, or Neutral)\")\n",
    "\n",
    "class Data(BaseModel):\n",
    "    \"\"\"Extracted data about sentences.\"\"\"\n",
    "    sentiments: List[SentimentAnalysisResponse]\n",
    "\n",
    "# Define the prompt template\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"Your task is to analyze the provided sentences written in African American English and identify the sentiment expressed by the author. \n",
    "            The sentiment should be classified as Positive, Negative, or Neutral for each sentence.\"\"\"\n",
    "        ),\n",
    "        (\"user\", \"{sentences}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the language model\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "\n",
    "# Create the runnable chain\n",
    "runnable = chat_template | model.with_structured_output(schema=Data)\n",
    "runnable_single = chat_template | model.with_structured_output(schema=SentimentAnalysisResponse)\n",
    "\n",
    "dataset = pd.read_csv('initial_2000_sentences.csv')[\"text\"]\n",
    "\n",
    "tweets = [\n",
    "    \"Bitch cant get shit from me but bubble gum nd hard dick from me told da bitch im tryna make a flip im shootin dice wit er rent money !\",\n",
    "    \"@islandboi_B yes that's what's up. Nothin like getting dressed up and getting some culture man.\",\n",
    "    \"Mixed huh !? Those black ass knees and elbows will give you away every time lol\"\n",
    "]\n",
    "\n",
    "#result = runnable.invoke({\"sentences\" : \"\\n\".join(dataset[:10].to_list())})\n",
    "\n",
    "print(f\"results are: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0b08167-4189-4d59-a8e0-379ecad51801",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 400/400 [04:51<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled dataset saved to ./labeled/GPT-3.5-Labels.csv\n",
      "Failed indices saved to ./labeled/failed_indices.csv\n",
      "Number of successfully processed sentences: 1800\n",
      "Number of failed sentences: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store the sentiments and their corresponding indices\n",
    "all_sentiments = []\n",
    "processed_indices = []\n",
    "failed_indices = []\n",
    "\n",
    "# Process the dataset in batches of 10\n",
    "for i in tqdm(range(0, len(dataset), 5)):\n",
    "    batch = dataset[i:i+5].to_list()\n",
    "    batch_indices = list(range(i, min(i+5, len(dataset))))\n",
    "    \n",
    "    try:\n",
    "        result = runnable.invoke({\"sentences\": \"\\n\".join(batch)})\n",
    "        \n",
    "        # Check if the number of returned sentiments matches the batch size\n",
    "        if len(result.sentiments) == len(batch):\n",
    "            all_sentiments.extend([response.sentiment for response in result.sentiments])\n",
    "            processed_indices.extend(batch_indices)\n",
    "        else:\n",
    "            # If the number of sentiments doesn't match, mark all as failed\n",
    "            failed_indices.extend(batch_indices)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {i}-{i+9}: {str(e)}\")\n",
    "        failed_indices.extend(batch_indices)\n",
    "\n",
    "# Create a new dataframe with successfully processed sentences and sentiments\n",
    "labeled_df = pd.DataFrame({\n",
    "    'index': processed_indices,\n",
    "    'text': dataset.iloc[processed_indices],\n",
    "    'sentiment': all_sentiments\n",
    "})\n",
    "\n",
    "# Sort the dataframe by the original index\n",
    "labeled_df = labeled_df.sort_values('index').reset_index(drop=True)\n",
    "\n",
    "# Save the labeled dataset to a CSV file\n",
    "output_path = './labeled/GPT-3.5-Labels.csv'\n",
    "labeled_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Labeled dataset saved to {output_path}\")\n",
    "\n",
    "# Save the failed indices to a separate file\n",
    "failed_indices_path = './labeled/failed_indices.csv'\n",
    "pd.DataFrame({'failed_index': failed_indices}).to_csv(failed_indices_path, index=False)\n",
    "\n",
    "print(f\"Failed indices saved to {failed_indices_path}\")\n",
    "print(f\"Number of successfully processed sentences: {len(processed_indices)}\")\n",
    "print(f\"Number of failed sentences: {len(failed_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92156b02-5035-4d92-917f-499229988d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 67/67 [00:40<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete labeled dataset saved to ./labeled/complete-2000-GPT-3.5.csv\n",
      "Total processed sentences: 2000\n",
      "Successfully labeled sentences: 1974\n",
      "Failed sentences: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the previously processed data\n",
    "labeled_df = pd.read_csv('./labeled/GPT-3.5-Labels.csv')\n",
    "failed_indices = pd.read_csv('./labeled/failed_indices.csv')['failed_index'].tolist()\n",
    "\n",
    "# Load the original dataset\n",
    "original_dataset = pd.read_csv('initial_2000_sentences.csv')[\"text\"]\n",
    "\n",
    "# Initialize lists to store the new sentiments and their corresponding indices\n",
    "new_sentiments = []\n",
    "new_processed_indices = []\n",
    "still_failed_indices = []\n",
    "\n",
    "# Process the failed sentences\n",
    "for i in tqdm(range(0, len(failed_indices), 3)):\n",
    "    batch_indices = failed_indices[i:i+3]\n",
    "    batch = original_dataset.iloc[batch_indices].tolist()\n",
    "    \n",
    "    try:\n",
    "        result = runnable.invoke({\"sentences\": \"\\n\".join(batch)})\n",
    "        \n",
    "        # Check if the number of returned sentiments matches the batch size\n",
    "        if len(result.sentiments) == len(batch):\n",
    "            new_sentiments.extend([response.sentiment for response in result.sentiments])\n",
    "            new_processed_indices.extend(batch_indices)\n",
    "        else:\n",
    "            # If the number of sentiments doesn't match, mark all as still failed\n",
    "            still_failed_indices.extend(batch_indices)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {i}-{i+2}: {str(e)}\")\n",
    "        still_failed_indices.extend(batch_indices)\n",
    "\n",
    "# Create a new dataframe with newly processed sentences and sentiments\n",
    "new_labeled_df = pd.DataFrame({\n",
    "    'index': new_processed_indices,\n",
    "    'text': original_dataset.iloc[new_processed_indices],\n",
    "    'sentiment': new_sentiments\n",
    "})\n",
    "\n",
    "# Combine the previously processed data with the newly processed data\n",
    "combined_df = pd.concat([labeled_df, new_labeled_df], ignore_index=True)\n",
    "\n",
    "# Sort the dataframe by the original index and reset the index\n",
    "combined_df = combined_df.sort_values('index').reset_index(drop=True)\n",
    "\n",
    "# If there are still failed indices, add them to the combined dataframe with NaN sentiment\n",
    "if still_failed_indices:\n",
    "    failed_df = pd.DataFrame({\n",
    "        'index': still_failed_indices,\n",
    "        'text': original_dataset.iloc[still_failed_indices],\n",
    "        'sentiment': pd.NA\n",
    "    })\n",
    "    combined_df = pd.concat([combined_df, failed_df], ignore_index=True)\n",
    "    combined_df = combined_df.sort_values('index').reset_index(drop=True)\n",
    "\n",
    "# Save the complete labeled dataset to a CSV file\n",
    "output_path = './labeled/complete-2000-GPT-3.5.csv'\n",
    "combined_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Complete labeled dataset saved to {output_path}\")\n",
    "print(f\"Total processed sentences: {len(combined_df)}\")\n",
    "print(f\"Successfully labeled sentences: {combined_df['sentiment'].notna().sum()}\")\n",
    "print(f\"Failed sentences: {combined_df['sentiment'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4097517e-6ebd-4c34-8fe8-a17f4a4cb8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_GPT_label(sentence):\n",
    "    completion = openai_client.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      temperature=0,\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Your task is to analyze the provided tweet written in African American English and identify the sentiment expressed by the author. The sentiment should be classified as Positive, Negative, or Neutral. Reply with just the sentiment.\"},\n",
    "        {\"role\": \"user\", \"content\": sentence}\n",
    "      ]\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3dc514cd-ffa0-4256-b510-4b02ebcdea0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anthropic_label(sentence):\n",
    "    message = anthropic_client.messages.create(\n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        max_tokens=10,\n",
    "        temperature=0,\n",
    "        system=\"Your task is to analyze the provided tweet written in African American English and identify the sentiment expressed by the author. The sentiment should be classified as Positive, Negative, or Neutral. Reply with just the sentiment.\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": sentence\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "447deff3-7a92-45f9-b2d7-9ec2eef9cb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_groq_label(sentences):\n",
    "   \n",
    "    chat_completion = groq_client.chat.completions.create(\n",
    "        \n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"Your task is to analyze the provided tweet written in African American English and identify the sentiment expressed by the author. The sentiment should be classified as Positive, Negative, or Neutral. Reply with just the sentiment in JSON. For example,\n",
    "                {'Sentence 1': 'Positive', 'Sentence 2 : Negative', 'Sentence 3' : 'Neutral' }.\"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": sentence,\n",
    "            }\n",
    "        ],\n",
    "\n",
    "        # The language model which will generate the completion.\n",
    "        model=\"llama3-70b-8192\",\n",
    "        temperature=0,\n",
    "\n",
    "        # If set, partial message deltas will be sent.\n",
    "        stream=False,\n",
    "    )\n",
    "\n",
    "    return chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6631909-43e4-4b3a-8788-d413ba188ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sentiment_labeling_pipeline(texts):\n",
    "    results = []\n",
    "    for text in texts:\n",
    "        gpt_label = get_GPT_label(text)\n",
    "        anthropic_label = get_anthropic_label(text)\n",
    "        groq_label = get_groq_label(text)\n",
    "        results.append([text, gpt_label, anthropic_label, groq_label])\n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "tweets = [\n",
    "    \"Bitch cant get shit from me but bubble gum nd hard dick from me told da bitch im tryna make a flip im shootin dice wit er rent money !\",\n",
    "    \"@islandboi_B yes that's what's up. Nothin like getting dressed up and getting some culture man.\",\n",
    "    \"Mixed huh !? Those black ass knees and elbows will give you away every time lol\"\n",
    "]\n",
    "\n",
    "# Get labeled tweets\n",
    "labeled_tweets = sentiment_labeling_pipeline(tweets)\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "columns = [\"Tweet\", \"GPT-3.5\", \"Anthropic\", \"Groq\"]\n",
    "df = pd.DataFrame(labeled_tweets, columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "89d7930e-f278-4698-8c1a-b24d00d42fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>GPT-3.5</th>\n",
       "      <th>Anthropic</th>\n",
       "      <th>Groq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bitch cant get shit from me but bubble gum nd ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@islandboi_B yes that's what's up. Nothin like...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mixed huh !? Those black ass knees and elbows ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet   GPT-3.5 Anthropic  \\\n",
       "0  Bitch cant get shit from me but bubble gum nd ...  Negative  Negative   \n",
       "1  @islandboi_B yes that's what's up. Nothin like...  Positive  Positive   \n",
       "2  Mixed huh !? Those black ass knees and elbows ...  Negative  Negative   \n",
       "\n",
       "       Groq  \n",
       "0  Negative  \n",
       "1  Positive  \n",
       "2  Positive  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8029840-3a93-445d-b269-49bbe9357685",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "augment",
   "language": "python",
   "name": "augmentation-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
